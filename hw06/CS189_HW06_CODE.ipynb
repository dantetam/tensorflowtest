{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic Imports and Data Setup\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "mnist = scipy.io.loadmat(\"./hw6_data_dist/letters_data.mat\")\n",
    "\n",
    "mnist_train_data = mnist[\"train_x\"]\n",
    "#mnist_train_labels = mnist[\"train_y\"] # 1 - 26\n",
    "mnist_test_data = mnist[\"test_x\"]\n",
    "mnist_raw_labels = mnist[\"train_y\"]\n",
    "\n",
    "#Append bias to training data\n",
    "ones = np.array([[1 for _ in range(len(mnist_train_data))]])\n",
    "mnist_train_data = np.concatenate((mnist_train_data, ones.T), axis=1)\n",
    "\n",
    "mnist_train_data, mnist_raw_labels = shuffle(\n",
    "    mnist_train_data, mnist_raw_labels, random_state=0)\n",
    "\n",
    "logging = True\n",
    "\n",
    "def logprint(msg):\n",
    "    if logging:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "def labelsToVector(labels):\n",
    "    result = []\n",
    "    for label in labels:\n",
    "        vec = [1 if i+1 == label else 0 for i in range(26)]\n",
    "        result.append(vec)\n",
    "    return result\n",
    "\n",
    "mnist_train_labels = labelsToVector(mnist_raw_labels)\n",
    "\n",
    "logprint(mnist_raw_labels[100])\n",
    "logprint(mnist_train_labels[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00396354,  0.02697234,  0.02327695, ..., -0.04033353,\n",
       "          0.04201523,  0.02732812],\n",
       "        [-0.00880124,  0.00061007, -0.01679176, ...,  0.06638868,\n",
       "          0.02122301, -0.0001514 ],\n",
       "        [ 0.04049719, -0.00195545,  0.03198255, ..., -0.10671998,\n",
       "         -0.03895394,  0.01085768],\n",
       "        ..., \n",
       "        [-0.00659104,  0.02128268,  0.03273203, ..., -0.00262291,\n",
       "         -0.02487332,  0.04742108],\n",
       "        [ 0.02953429, -0.02234793,  0.0117783 , ..., -0.00015394,\n",
       "         -0.00933957,  0.01959741],\n",
       "        [-0.02433439, -0.08169252,  0.02198847, ...,  0.00478221,\n",
       "         -0.09231498,  0.01993075]]),\n",
       " array([[ 0.03590482, -0.0520396 , -0.06043766, ...,  0.08255051,\n",
       "          0.01542365,  0.06019421],\n",
       "        [-0.01370881,  0.07813921,  0.06126528, ...,  0.01460649,\n",
       "          0.0638195 , -0.02265309],\n",
       "        [ 0.00382901,  0.06679599, -0.10522025, ..., -0.0382656 ,\n",
       "          0.1488184 ,  0.04465715],\n",
       "        ..., \n",
       "        [ 0.00642352,  0.02028853,  0.01481156, ...,  0.14473008,\n",
       "         -0.08196895,  0.07214716],\n",
       "        [ 0.02155174,  0.00290557, -0.09927121, ...,  0.03336696,\n",
       "         -0.05009879, -0.03173095],\n",
       "        [-0.0277876 ,  0.04546859,  0.02979282, ...,  0.03897067,\n",
       "         -0.09803717,  0.07235724]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main training of the network by SGD\n",
    "\n",
    "#Note that this works for matrices by element\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "#z is predicted, y is actual\n",
    "def crossEntropy(z, y):\n",
    "    assert len(z) == len(y)\n",
    "    entropy = 0\n",
    "    for j in range(len(z)):\n",
    "        entropy += y[j] * np.log(z[j]) + (1 - y[j]) * np.log(1 - z[j])\n",
    "    return -entropy    \n",
    "\n",
    "def trainNeuralNetwork(images, labels, params=None):\n",
    "    #V = np.random.rand(200, 785)\n",
    "    #W = np.random.rand(26, 201)\n",
    "    \n",
    "    V = np.random.normal(0, math.sqrt(1/785), (200,785))\n",
    "    W = np.random.normal(0, math.sqrt(1/201), (26,201))\n",
    "    \n",
    "    iterations = 100\n",
    "    while iterations > 0:\n",
    "        #Choose a random index for SGD, we'll use this to update\n",
    "        index = int(np.random.random() * len(images))\n",
    "        X_i = images[index] #The data\n",
    "        y_i = labels[index] #The correct value as a vector\n",
    "        \n",
    "        #Compute the forward pass by simple matrix multiplication\n",
    "        #hidden = V * X_i\n",
    "        #200 x 1 = 200 x 785 * 785 x 1\n",
    "        hidden = np.dot(V, X_i)\n",
    "        hidden_activated = np.tanh(hidden)\n",
    "        #V 201 x 1\n",
    "        hidden_activated_bias = np.concatenate((hidden_activated, np.array([1])))\n",
    "        \n",
    "        #output = W * hidden_bias\n",
    "        #26 x 1 = 26 x 201 * 201 x 1\n",
    "        output = np.dot(W, hidden_activated_bias)\n",
    "        output_activated = sigmoid(output)\n",
    "        \n",
    "        entropy = crossEntropy(output_activated, y_i)\n",
    "        \n",
    "        #SGD\n",
    "        \n",
    "        W_copy = np.array(W)\n",
    "        \n",
    "        derivatives_store = []\n",
    "        \n",
    "        for outputIndex in range(len(output)):\n",
    "            left = - y_i[outputIndex] / output_activated[outputIndex] + (1 - y_i[outputIndex]) / (1 - output_activated[outputIndex])\n",
    "            middle = output_activated[outputIndex] * (1 - output_activated[outputIndex])\n",
    "            derivatives_store.append(left * middle)\n",
    "        \n",
    "        for outputIndex in range(len(output)): #for every unit in the output layer\n",
    "            for hiddenIndex in range(len(hidden)):\n",
    "                #left = - y_i[outputIndex] / output_activated[outputIndex] + (1 - y_i[outputIndex]) / (1 - output_activated[outputIndex])\n",
    "                #middle = output_activated[outputIndex] * (1 - output_activated[outputIndex])\n",
    "                leftmiddle = derivatives_store[outputIndex]\n",
    "                right = hidden_activated[hiddenIndex]\n",
    "                d_e_weight = leftmiddle * right\n",
    "                W_copy[outputIndex][hiddenIndex] -= learning_rate * d_e_weight\n",
    "        \n",
    "        for hiddenIndex in range(len(hidden)):\n",
    "            for inputIndex in range(len(X_i) - 1):\n",
    "                sum_outgoing = 0\n",
    "                for outputIndex in range(26):\n",
    "                    sum_outgoing += derivatives_store[outputIndex] * W[outputIndex][hiddenIndex]\n",
    "                middle = hidden_activated[hiddenIndex]\n",
    "                middle = 1 - middle*middle\n",
    "                right = X_i[inputIndex]\n",
    "                d_e_weight = sum_outgoing * middle * right\n",
    "                W_copy[outputIndex][hiddenIndex] -= learning_rate * d_e_weight\n",
    "        \n",
    "        iterations -= 1\n",
    "        \n",
    "    return V, W\n",
    "\n",
    "trainNeuralNetwork(mnist_train_data, mnist_train_labels, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.76159416  0.96402758  0.99505475  0.9993293 ]\n",
      " [ 0.9999092   0.99998771  0.99999834  0.99999977]]\n"
     ]
    }
   ],
   "source": [
    "print(np.tanh(np.array([[1,2,3,4],[5,6,7,8]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictNeuralNetwork(images, V, W):\n",
    "\n",
    "def calculateVal:    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
