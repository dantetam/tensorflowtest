{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'race': 'Black', 'occupation': 'Other-service', 'workclass': 'Private', 'marital-status': 'Never-married', 'sex': 'Male', 'label': '0', 'age': '59', 'hours-per-week': '50', 'education-num': '5', 'relationship': 'Not-in-family', 'native-country': 'United-States', 'education': '9th', 'fnlwgt': '307423', 'capital-loss': '0', 'capital-gain': '0'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import csv\n",
    "import sklearn\n",
    "import sklearn.feature_extraction\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "spam = scipy.io.loadmat(\"./dist/spam_data.mat\")\n",
    "census_train = csv.DictReader(open(\"./census_training_data.csv\"))\n",
    "census_test = csv.DictReader(open(\"./census_test_data.csv\"))\n",
    "titanic_train = csv.DictReader(open(\"./titanic_training_data.csv\"))\n",
    "titanic_test = csv.DictReader(open(\"./titanic_testing_data.csv\"))\n",
    "\n",
    "firstTest = None\n",
    "for row in census_train:\n",
    "    print(row)\n",
    "    firstTest = row\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sample sequence X is empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b640deff0ba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcensus_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mc:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\dict_vectorizer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mFeature\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0malways\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\dict_vectorizer.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, fitting)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sample sequence X is empty.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrombuffer_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample sequence X is empty."
     ]
    }
   ],
   "source": [
    "\n",
    "vec = sklearn.feature_extraction.DictVectorizer()\n",
    "X = vec.fit_transform(census_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.split_rule = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.label = None \n",
    "        self.guess_data = None\n",
    "\n",
    "def nodeDecision(node, data):\n",
    "    if node.guess_data != None:\n",
    "        guess = random.random()\n",
    "        cdf = 0\n",
    "        for k,v in node.guess_data.items():\n",
    "            cdf += v\n",
    "            if guess <= cdf:\n",
    "                return k\n",
    "    elif node.split_rule != None:\n",
    "        if data[node.split_rule[0]] == node.split_rule[1]:\n",
    "            return nodeDecision(node.right, data)\n",
    "        else:\n",
    "            return nodeDecision(node.left, data)\n",
    "    else:\n",
    "        return node.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where left and right are maps from labels -> frequencies\n",
    "def impurity(left, right):\n",
    "    leftEn = 0\n",
    "    rightEn = 0\n",
    "    leftSum = 0\n",
    "    rightSum = 0\n",
    "    for k,v in left.items():\n",
    "        p_c = v / len(left)\n",
    "        if v == 0: continue\n",
    "        leftEn += p_c * np.log2(p_c)\n",
    "        leftSum += v\n",
    "    for k,v in right.items():\n",
    "        p_c = v / len(right)\n",
    "        if v == 0: continue\n",
    "        rightEn += p_c * np.log2(p_c)\n",
    "        rightSum += v\n",
    "    weightSum = leftSum * leftEn + rightSum * rightEn\n",
    "    return weightSum / (leftEn + rightEn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 14.0\n",
      "8 6\n",
      "0 0\n",
      "14.0\n",
      "1 0 14.0\n",
      "8 6\n",
      "0 0\n",
      "14.0\n",
      "2 0 7.40884530065\n",
      "5 3\n",
      "3 3\n",
      "7.40884530065\n",
      "3 0 13.1586730345\n",
      "7 5\n",
      "1 1\n",
      "13.1586730345\n",
      "0 0 8.26185950714\n",
      "3 4\n",
      "1 0\n",
      "8.26185950714\n",
      "1 0 8.26185950714\n",
      "3 4\n",
      "1 0\n",
      "8.26185950714\n",
      "2 0 4.26185950714\n",
      "3 0\n",
      "1 4\n",
      "4.26185950714\n",
      "3 0 8.26185950714\n",
      "3 4\n",
      "1 0\n",
      "8.26185950714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'guess'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return None if the data is essentially pure across \n",
    "def segmenter(data, labels):\n",
    "    uniqueLabels = set(labels)\n",
    "    minBadness = -1\n",
    "    maxLabelIndex = -1\n",
    "    maxLabelSplitDir = -1\n",
    "    \n",
    "    #TODO: Confirm type of data and figure out type of labels\n",
    "    \n",
    "    if len(labels) == 0:\n",
    "        return None\n",
    "    \n",
    "    firstLabel = labels[0]\n",
    "    pure = True\n",
    "    for label in labels:\n",
    "        if firstLabel != label:\n",
    "            pure = False\n",
    "            break\n",
    "    if pure:\n",
    "        return None\n",
    "    \n",
    "    featuresEqual = True\n",
    "    for featureIndex in range(len(data[0])):\n",
    "        equalNum = data[0][featureIndex]\n",
    "        equal = True\n",
    "        for dataIndex in range(len(data)):\n",
    "            equal = equal and (equalNum == data[dataIndex][featureIndex]) \n",
    "        if not equal: \n",
    "            featuresEqual = False\n",
    "            break\n",
    "        featuresEqual = featuresEqual and equal\n",
    "    if featuresEqual:\n",
    "        return \"guess\"\n",
    "    \n",
    "    for featureIndex in range(len(data[0])):\n",
    "        splits = [0] #With binary variables, a 0 split \n",
    "                        #is equivalent to a 1 split \n",
    "        for split in splits:\n",
    "            left = dict()\n",
    "            right = dict()\n",
    "            for uniqueLabel in uniqueLabels:\n",
    "                left[uniqueLabel] = 0\n",
    "                right[uniqueLabel] = 0\n",
    "            \n",
    "            \"\"\"\n",
    "            for dataIndex in range(len(data)):\n",
    "                if data[dataIndex][labelIndex] != split:\n",
    "                    for labelIndex2 in range(len(labels)):\n",
    "                        left[labelIndex2] += 1\n",
    "                else:\n",
    "                    for labelIndex2 in range(len(labels)):\n",
    "                        right[labelIndex2] += 1\n",
    "            \"\"\"\n",
    "            \n",
    "            for dataIndex in range(len(data)):\n",
    "                if data[dataIndex][featureIndex] != split:\n",
    "                    left[labels[dataIndex]] += 1\n",
    "                else:\n",
    "                    right[labels[dataIndex]] += 1\n",
    "                    \n",
    "            badness = impurity(left, right)\n",
    "            \n",
    "            print(str(featureIndex) + \" \" + str(split) + \" \" + str(badness))\n",
    "            print(str(left[\"a\"]) + \" \" + str(left[\"b\"]))\n",
    "            print(str(right[\"a\"]) + \" \" + str(right[\"b\"]))\n",
    "            print(badness)\n",
    "            #print(\"----------\")\n",
    "            \n",
    "            if badness < minBadness or maxLabelIndex == -1:\n",
    "                minBadness = badness\n",
    "                maxLabelIndex = featureIndex\n",
    "                maxLabelSplitDir = split\n",
    "    \n",
    "    return (maxLabelIndex, maxLabelSplitDir)\n",
    "\n",
    "test = np.array([\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,0],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,0],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1]\n",
    "    ])\n",
    "segmenter(test, [\"a\",\"a\",\"b\",\"a\",\"b\",\"a\",\"b\",\"b\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\"])\n",
    "\n",
    "test = np.array([\n",
    "        [1,1,0,1],\n",
    "        [1,0,1,1],\n",
    "        [0,1,1,1],\n",
    "        [1,1,1,0],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,1]\n",
    "    ])\n",
    "segmenter(test, [\"a\",\"a\",\"a\",\"a\",\"b\",\"b\",\"b\",\"b\"])\n",
    "\n",
    "test = np.array([\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "    ])\n",
    "segmenter(test, [\"a\",\"a\",\"a\",\"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 14.0\n",
      "8 6\n",
      "0 0\n",
      "14.0\n",
      "1 0 14.0\n",
      "8 6\n",
      "0 0\n",
      "14.0\n",
      "2 0 7.40884530065\n",
      "5 3\n",
      "3 3\n",
      "7.40884530065\n",
      "3 0 13.1586730345\n",
      "7 5\n",
      "1 1\n",
      "13.1586730345\n",
      "---------------\n",
      "For data set: \n",
      "[[1 1 0 1]\n",
      " [1 1 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 1]\n",
      " [1 1 0 0]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 0 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n",
      "and labels: \n",
      "['a' 'a' 'b' 'a' 'b' 'a' 'b' 'b' 'b' 'a' 'a' 'b' 'a' 'a']\n",
      "A decision rule was found: \n",
      "(2, 0)\n",
      "8 6\n",
      "---------------\n",
      "For data set: \n",
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n",
      "and labels: \n",
      "['b', 'a', 'a', 'b', 'a', 'b', 'a', 'a']\n",
      "A guessing rule was found for non-separable data: \n",
      "{'b': 0.375, 'a': 0.625}\n",
      "0 0 6.0\n",
      "3 3\n",
      "0 0\n",
      "6.0\n",
      "1 0 6.0\n",
      "3 3\n",
      "0 0\n",
      "6.0\n",
      "2 0 6.0\n",
      "0 0\n",
      "3 3\n",
      "6.0\n",
      "3 0 2.0\n",
      "2 2\n",
      "1 1\n",
      "2.0\n",
      "---------------\n",
      "For data set: \n",
      "[[1 1 0 1]\n",
      " [1 1 0 0]\n",
      " [1 1 0 1]\n",
      " [1 1 0 1]\n",
      " [1 1 0 0]\n",
      " [1 1 0 1]]\n",
      "and labels: \n",
      "['a', 'a', 'b', 'b', 'b', 'a']\n",
      "A decision rule was found: \n",
      "(3, 0)\n",
      "4 2\n",
      "---------------\n",
      "For data set: \n",
      "[[1 1 0 1]\n",
      " [1 1 0 1]\n",
      " [1 1 0 1]\n",
      " [1 1 0 1]]\n",
      "and labels: \n",
      "['a', 'b', 'b', 'a']\n",
      "A guessing rule was found for non-separable data: \n",
      "{'a': 0.5, 'b': 0.5}\n",
      "---------------\n",
      "For data set: \n",
      "[[1 1 0 0]\n",
      " [1 1 0 0]]\n",
      "and labels: \n",
      "['a', 'b']\n",
      "A guessing rule was found for non-separable data: \n",
      "{'a': 0.5, 'b': 0.5}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialNode = Node()\n",
    "\n",
    "def train(node, data, labels, levels=3):\n",
    "    if levels <= 0: return\n",
    "    decision = segmenter(data, labels)\n",
    "    print(\"---------------\")\n",
    "    print(\"For data set: \")\n",
    "    print(data)\n",
    "    print(\"and labels: \")\n",
    "    print(labels)\n",
    "    if decision != None: #A split rule was found for a non-pure node\n",
    "        if decision == \"guess\": #It's a decision for non-separable data: \n",
    "            uniqueLabels = set(labels)\n",
    "            print(\"A guessing rule was found for non-separable data: \")\n",
    "            node.guess_data = dict()\n",
    "            for label in uniqueLabels:\n",
    "                node.guess_data[label] = 0\n",
    "            for label in labels:\n",
    "                node.guess_data[label] += 1\n",
    "            for label in uniqueLabels:\n",
    "                node.guess_data[label] /= float(len(labels))\n",
    "            print(node.guess_data)\n",
    "        else:\n",
    "            print(\"A decision rule was found: \")\n",
    "            print(decision)\n",
    "            node.split_rule = decision\n",
    "            node.left = Node()\n",
    "            node.right = Node()\n",
    "            leftData = []\n",
    "            rightData = []\n",
    "            leftLabels = []\n",
    "            rightLabels = []\n",
    "            for dataIndex in range(len(data)):\n",
    "                if data[dataIndex][decision[0]] == decision[1]:\n",
    "                    rightData.append(data[dataIndex])\n",
    "                    rightLabels.append(labels[dataIndex])\n",
    "                else:\n",
    "                    leftData.append(data[dataIndex])\n",
    "                    leftLabels.append(labels[dataIndex])\n",
    "            print(str(len(leftData)) + \" \" + str(len(rightData)))\n",
    "            leftData = np.array(leftData)\n",
    "            rightData = np.array(rightData)\n",
    "            train(node.left, leftData, leftLabels, levels - 1)\n",
    "            train(node.right, rightData, rightLabels, levels - 1)\n",
    "    else:\n",
    "        print(\"No decision was found for a pure node\")\n",
    "        return\n",
    "    \n",
    "testData = np.array([\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,0],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,0],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1]\n",
    "    ])\n",
    "testLabels = np.array(\n",
    "    [\"a\",\"a\",\"b\",\"a\",\"b\",\"a\",\"b\",\"b\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\"]\n",
    ")\n",
    "\n",
    "train(initialNode, testData, testLabels, 3)\n",
    "\n",
    "nodeDecision(initialNode, [1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
