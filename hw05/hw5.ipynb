{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import csv\n",
    "import sklearn\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "spam = scipy.io.loadmat(\"./dist/spam_data.mat\")\n",
    "census_train = csv.DictReader(open(\"./census_training_data.csv\"))\n",
    "census_test = csv.DictReader(open(\"./census_test_data.csv\"))\n",
    "titanic_train = csv.DictReader(open(\"./titanic_training_data.csv\"))\n",
    "titanic_test = csv.DictReader(open(\"./titanic_testing_data.csv\"))\n",
    "\n",
    "def dictReaderToDictList(obj):\n",
    "    arrayDicts = []\n",
    "    for row in obj:\n",
    "        arrayDicts.append(row)\n",
    "    return arrayDicts\n",
    "\n",
    "def findMostCommonValue(dictVectorized):\n",
    "    listFeatureModes = []\n",
    "    for featureIndex in range(len(dictVectorized[0])):\n",
    "        temp = dict()\n",
    "        for dataIndex in range(len(dictVectorized)):\n",
    "            featureValue = dictVectorized[dataIndex][featureIndex]\n",
    "            if featureValue not in temp:\n",
    "                temp[featureValue] = 0\n",
    "            temp[featureValue] += 1\n",
    "        maxFeatureValue = -1\n",
    "        maxFeatureKey = -1\n",
    "        for k,v in temp.items():\n",
    "            if v > maxFeatureValue or maxFeatureKey == -1:\n",
    "                maxFeatureValue = v\n",
    "                maxFeatureKey = k\n",
    "        listFeatureModes.append(maxFeatureKey)\n",
    "    return listFeatureModes\n",
    "\n",
    "logging = False\n",
    "\n",
    "def logprint(message):\n",
    "    if logging:\n",
    "        print(message)\n",
    "    \n",
    "test = np.array([[0, 0, 1], [0, 0, 1], [2, 1, 0]])\n",
    "print(len(test[0]))\n",
    "print(findMostCommonValue(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hours-per-week': '44', 'sex': 'Male', 'race': 'White', 'relationship': 'Husband', 'label': '1', 'marital-status': 'Married-civ-spouse', 'workclass': 'Private', 'education': 'Assoc-acdm', 'fnlwgt': '155489', 'native-country': 'United-States', 'capital-gain': '0', 'capital-loss': '0', 'age': '46', 'education-num': '12', 'occupation': 'Craft-repair'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "spam = scipy.io.loadmat(\"./dist/spam_data.mat\")\n",
    "census_train = csv.DictReader(open(\"./census_training_data.csv\"))\n",
    "census_test = csv.DictReader(open(\"./census_test_data.csv\"))\n",
    "titanic_train = csv.DictReader(open(\"./titanic_training_data.csv\"))\n",
    "titanic_test = csv.DictReader(open(\"./titanic_testing_data.csv\"))\n",
    "\n",
    "arrayDictCensusTrain = dictReaderToDictList(census_train)\n",
    "print(arrayDictCensusTrain[567])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "22267\n",
      "[[ 0.  0.  0. ...,  0.  0.  1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncensus_train = csv.DictReader(open(\"./census_training_data.csv\"))\\nprocessed_census_train = []\\ni = 0\\nfor row in census_train:\\n    if i >= 3: break\\n    i += 1\\n    processed_census_train.append(vec.transform(row))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "spam = scipy.io.loadmat(\"./dist/spam_data.mat\")\n",
    "census_train = csv.DictReader(open(\"./census_training_data.csv\"))\n",
    "census_test = csv.DictReader(open(\"./census_test_data.csv\"))\n",
    "titanic_train = csv.DictReader(open(\"./titanic_training_data.csv\"))\n",
    "titanic_test = csv.DictReader(open(\"./titanic_testing_data.csv\"))\n",
    "\n",
    "census_vec = sklearn.feature_extraction.DictVectorizer(sparse=False)\n",
    "census_vec.fit(census_train)\n",
    "\n",
    "print(census_vec)\n",
    "\n",
    "randTest = {'label': '0', 'hours-per-week': '50', 'education-num': '5', 'occupation': 'Other-service', 'marital-status': 'Never-married', 'relationship': 'Not-in-family', 'native-country': 'United-States', 'sex': 'Male', 'age': '59', 'workclass': 'Private', 'fnlwgt': '307423', 'race': 'Black', 'education': '9th', 'capital-loss': '0', 'capital-gain': '0'}\n",
    "otherTest = {'label': '0', 'hours-per-week': '45', 'education-num': '12', 'occupation': 'Sales', 'marital-status': 'Married-civ-spouse', 'relationship': 'Husband', 'native-country': 'United-States', 'sex': 'Male', 'age': '51', 'workclass': 'Without-pay', 'fnlwgt': '124963', 'race': 'White', 'education': 'Assoc-acdm', 'capital-loss': '0', 'capital-gain': '0'}\n",
    "\n",
    "temp = census_vec.transform(randTest)\n",
    "\n",
    "print(temp)\n",
    "print(len(temp[0]))\n",
    "print(census_vec.transform(otherTest))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "census_train = csv.DictReader(open(\"./census_training_data.csv\"))\n",
    "processed_census_train = []\n",
    "i = 0\n",
    "for row in census_train:\n",
    "    if i >= 3: break\n",
    "    i += 1\n",
    "    processed_census_train.append(vec.transform(row))\n",
    "\"\"\"\n",
    "\n",
    "#np.savetxt(\"preprocessed_census_train.csv\", processed_census_train, fmt=\"%i,%i\", delimiter=\",\", header=\"Id,Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Thu Mar 16 00:54:38 2017', '__version__': '1.0', 'training_labels': array([[1, 1, 1, ..., 0, 0, 0]], dtype=int64), '__globals__': [], 'test_data': array([[ 0.,  0.,  0., ...,  2.,  1.,  1.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]]), 'training_data': array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  4.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  2.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  2.]])}\n",
      "{'hours-per-week': 40, 'occupation': 'Exec-managerial', 'education': 'Bachelors', 'age': 55, 'workclass': 'Private', 'sex': 'Male', 'native-country': 'United-States', 'relationship': 'Husband', 'capital-gain': 0, 'race': 'White', 'marital-status': 'Married-civ-spouse', 'capital-loss': 0, 'fnlwgt': 349304, 'education-num': 13}\n"
     ]
    }
   ],
   "source": [
    "f=pd.read_csv(\"./census_training_data.csv\")\n",
    "keep_census_col = [\n",
    "            'age',\n",
    "            'workclass',\n",
    "            'fnlwgt',\n",
    "            'education',\n",
    "            'education-num',\n",
    "            'marital-status',\n",
    "            'occupation',\n",
    "            'relationship',\n",
    "            'race',\n",
    "            'sex',\n",
    "            'capital-gain',\n",
    "            'capital-loss',\n",
    "            'hours-per-week',\n",
    "            'native-country'\n",
    "           ]\n",
    "new_f = f[keep_census_col]\n",
    "\n",
    "census_train_labels = f['label'].tolist()\n",
    "\n",
    "def collateDataFrame(frame):\n",
    "    rows = -1\n",
    "    results = []\n",
    "    for columnName, dictColumnData in frame.items():\n",
    "        if rows == -1:\n",
    "            rows = len(dictColumnData)\n",
    "            results = [{} for _ in range(rows)]\n",
    "        for index, value in dictColumnData.items():\n",
    "            results[index][columnName] = value\n",
    "    return results      \n",
    "        \n",
    "census_train_csv = collateDataFrame(new_f)\n",
    "\n",
    "spam_train_data = spam[\"training_data\"]\n",
    "spam_train_labels = spam[\"training_labels\"][0]\n",
    "\n",
    "spam_test_data = spam[\"test_data\"]\n",
    "\n",
    "print(spam)\n",
    "\n",
    "#new_f.to_csv(\"newFile.csv\", index=False)\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "f=pd.read_csv(\"./census_test_data.csv\")\n",
    "\n",
    "new_f = f[keep_census_col]\n",
    "census_test_csv = collateDataFrame(new_f)\n",
    "\n",
    "print(census_test_csv[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare',\n",
      "       'cabin', 'embarked'],\n",
      "      dtype='object')\n",
      "1000\n",
      "{'sibsp': 0.0, 'pclass': 2.0, 'parch': 0.0, 'fare': 33.0, 'embarked': 'S', 'sex': 'female', 'age': nan}\n",
      "0          NaN\n",
      "1          NaN\n",
      "2          NaN\n",
      "3          NaN\n",
      "4          NaN\n",
      "5          NaN\n",
      "6          NaN\n",
      "7          NaN\n",
      "8          NaN\n",
      "9          E45\n",
      "10         NaN\n",
      "11         NaN\n",
      "12         NaN\n",
      "13         NaN\n",
      "14     B58 B60\n",
      "15         B30\n",
      "16         NaN\n",
      "17         NaN\n",
      "18         E46\n",
      "19         NaN\n",
      "20         NaN\n",
      "21         NaN\n",
      "22         NaN\n",
      "23         NaN\n",
      "24         NaN\n",
      "25         D20\n",
      "26          F2\n",
      "27         NaN\n",
      "28         E25\n",
      "29         NaN\n",
      "        ...   \n",
      "970        NaN\n",
      "971        NaN\n",
      "972        NaN\n",
      "973        NaN\n",
      "974        E17\n",
      "975        D30\n",
      "976        D50\n",
      "977        NaN\n",
      "978        A21\n",
      "979        NaN\n",
      "980        NaN\n",
      "981         G6\n",
      "982        NaN\n",
      "983    B96 B98\n",
      "984        NaN\n",
      "985        NaN\n",
      "986        NaN\n",
      "987        NaN\n",
      "988        NaN\n",
      "989        NaN\n",
      "990        NaN\n",
      "991        NaN\n",
      "992        NaN\n",
      "993        NaN\n",
      "994        NaN\n",
      "995        NaN\n",
      "996        NaN\n",
      "997        NaN\n",
      "998        NaN\n",
      "999        NaN\n",
      "Name: cabin, dtype: object\n",
      "[567, 10, 122, 152, 162, 169, 258, 308, 311, 333, 343, 429, 467, 485, 495, 569, 576, 600, 750, 762, 792, 828, 871, 901, 905, 988, 993, 3, 6, 20, 33, 36, 39, 42, 43, 47, 48, 51, 64, 68, 77, 84, 88, 92, 108, 112, 114, 116, 129, 132]\n",
      "{'sibsp': 0.0, 'pclass': 2.0, 'parch': 0.0, 'fare': 13.0, 'embarked': 'S', 'sex': 'female', 'age': 28.0}\n",
      "[nan]\n",
      "{'sibsp': 1.0, 'pclass': 3.0, 'parch': 1.0, 'fare': 21.074999999999999, 'embarked': 'S', 'sex': 'female', 'age': 3.0}\n",
      "{'sibsp': 2.0, 'pclass': 3.0, 'parch': 2.0, 'fare': 34.375, 'embarked': 'S', 'sex': 'female', 'age': 9.0}\n",
      "310\n"
     ]
    }
   ],
   "source": [
    "g=pd.read_csv(\"./titanic_training_data.csv\")\n",
    "print(g.keys())\n",
    "keep_titanic_col = [\n",
    "            'pclass',\n",
    "            'age',\n",
    "            'sex',\n",
    "            'sibsp',\n",
    "            'parch',\n",
    "            #'ticket',\n",
    "            'fare',\n",
    "            #'cabin',\n",
    "            'embarked'\n",
    "           ]\n",
    "new_g = g[keep_titanic_col]\n",
    "\n",
    "titanic_train_labels_pre = g['survived'].tolist()  \n",
    "titanic_train_labels = []    \n",
    "\n",
    "titanic_train_csv = collateDataFrame(new_g)\n",
    "\n",
    "print(len(titanic_train_csv))\n",
    "print(titanic_train_csv[567])\n",
    "\n",
    "print(g[\"cabin\"])\n",
    "\n",
    "def dataDistance(data1, data2):\n",
    "    dist = 0\n",
    "    for k,v in data1.items():\n",
    "        if data1[k] != data2[k]:\n",
    "            dist += 1\n",
    "    return dist\n",
    "\n",
    "import operator\n",
    "\n",
    "def findNearestNeighbors(data, dataPoint, desiredNum = 50):\n",
    "    dataRankedByDist = dict()\n",
    "    for i in range(len(data)):\n",
    "        otherDataPoint = data[i]\n",
    "        dataRankedByDist[i] = dataDistance(dataPoint, otherDataPoint)\n",
    "    sorted_x = sorted(dataRankedByDist.items(), key=operator.itemgetter(1))\n",
    "    desired = sorted_x[0:desiredNum]\n",
    "    return [pair[0] for pair in desired]\n",
    "\n",
    "print(findNearestNeighbors(titanic_train_csv, titanic_train_csv[567], 50))\n",
    "\n",
    "def fillInMissingData(data, dataPoint):\n",
    "    copy = dict(dataPoint)\n",
    "    listIndicesNN = findNearestNeighbors(data, dataPoint, 50)\n",
    "    for feature in dataPoint.keys():\n",
    "        candidates = dict()\n",
    "        for dataIndex in listIndicesNN:\n",
    "            sample = data[dataIndex][feature]\n",
    "            #print(sample)\n",
    "            if not pd.isnull(sample):\n",
    "                if sample not in candidates:\n",
    "                    candidates[sample] = 0\n",
    "                candidates[sample] += 1\n",
    "        maxLabel = -1\n",
    "        maxLabelCount = -1\n",
    "        for k,v in candidates.items():\n",
    "            if maxLabel == -1 or v > maxLabelCount:\n",
    "                maxLabel = k\n",
    "                maxLabelCount = v\n",
    "        copy[feature] = maxLabel\n",
    "    return copy\n",
    "\n",
    "print(fillInMissingData(titanic_train_csv, titanic_train_csv[567]))\n",
    "\n",
    "print([label for label in titanic_train_labels_pre if np.isnan(label)])\n",
    "    \n",
    "titanic_train_imputed_data = []\n",
    "for i in range(len(titanic_train_csv)):\n",
    "    if np.isnan(titanic_train_labels_pre[i]): continue\n",
    "    imputed = fillInMissingData(titanic_train_csv, titanic_train_csv[i])\n",
    "    titanic_train_imputed_data.append(imputed)\n",
    "    titanic_train_labels.append(titanic_train_labels_pre[i])\n",
    "\n",
    "print(titanic_train_imputed_data[667])\n",
    "\n",
    "#--------------------------------\n",
    "\n",
    "f=pd.read_csv(\"./titanic_testing_data.csv\")\n",
    "\n",
    "new_f = f[keep_titanic_col]\n",
    "titanic_test_csv = collateDataFrame(new_f)\n",
    "\n",
    "print(titanic_test_csv[100])\n",
    "print(len(titanic_test_csv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4.60000000e+01   0.00000000e+00   0.00000000e+00   1.20000000e+01\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.55489000e+05   4.40000000e+01   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "108\n",
      "[[  3.40000000e+01   0.00000000e+00   1.88700000e+03   1.00000000e+01\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    2.07668000e+05   4.00000000e+01   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    1.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "[('age', 0), ('capital-gain', 1), ('capital-loss', 2), ('education-num', 3), ('education=10th', 4), ('education=11th', 5), ('education=12th', 6), ('education=1st-4th', 7), ('education=5th-6th', 8), ('education=7th-8th', 9), ('education=9th', 10), ('education=Assoc-acdm', 11), ('education=Assoc-voc', 12), ('education=Bachelors', 13), ('education=Doctorate', 14), ('education=HS-grad', 15), ('education=Masters', 16), ('education=Preschool', 17), ('education=Prof-school', 18), ('education=Some-college', 19), ('fnlwgt', 20), ('hours-per-week', 21), ('marital-status=Divorced', 22), ('marital-status=Married-AF-spouse', 23), ('marital-status=Married-civ-spouse', 24), ('marital-status=Married-spouse-absent', 25), ('marital-status=Never-married', 26), ('marital-status=Separated', 27), ('marital-status=Widowed', 28), ('native-country=?', 29), ('native-country=Cambodia', 30), ('native-country=Canada', 31), ('native-country=China', 32), ('native-country=Columbia', 33), ('native-country=Cuba', 34), ('native-country=Dominican-Republic', 35), ('native-country=Ecuador', 36), ('native-country=El-Salvador', 37), ('native-country=England', 38), ('native-country=France', 39), ('native-country=Germany', 40), ('native-country=Greece', 41), ('native-country=Guatemala', 42), ('native-country=Haiti', 43), ('native-country=Holand-Netherlands', 44), ('native-country=Honduras', 45), ('native-country=Hong', 46), ('native-country=Hungary', 47), ('native-country=India', 48), ('native-country=Iran', 49), ('native-country=Ireland', 50), ('native-country=Italy', 51), ('native-country=Jamaica', 52), ('native-country=Japan', 53), ('native-country=Laos', 54), ('native-country=Mexico', 55), ('native-country=Nicaragua', 56), ('native-country=Outlying-US(Guam-USVI-etc)', 57), ('native-country=Peru', 58), ('native-country=Philippines', 59), ('native-country=Poland', 60), ('native-country=Portugal', 61), ('native-country=Puerto-Rico', 62), ('native-country=Scotland', 63), ('native-country=South', 64), ('native-country=Taiwan', 65), ('native-country=Thailand', 66), ('native-country=Trinadad&Tobago', 67), ('native-country=United-States', 68), ('native-country=Vietnam', 69), ('native-country=Yugoslavia', 70), ('occupation=?', 71), ('occupation=Adm-clerical', 72), ('occupation=Armed-Forces', 73), ('occupation=Craft-repair', 74), ('occupation=Exec-managerial', 75), ('occupation=Farming-fishing', 76), ('occupation=Handlers-cleaners', 77), ('occupation=Machine-op-inspct', 78), ('occupation=Other-service', 79), ('occupation=Priv-house-serv', 80), ('occupation=Prof-specialty', 81), ('occupation=Protective-serv', 82), ('occupation=Sales', 83), ('occupation=Tech-support', 84), ('occupation=Transport-moving', 85), ('race=Amer-Indian-Eskimo', 86), ('race=Asian-Pac-Islander', 87), ('race=Black', 88), ('race=Other', 89), ('race=White', 90), ('relationship=Husband', 91), ('relationship=Not-in-family', 92), ('relationship=Other-relative', 93), ('relationship=Own-child', 94), ('relationship=Unmarried', 95), ('relationship=Wife', 96), ('sex=Female', 97), ('sex=Male', 98), ('workclass=?', 99), ('workclass=Federal-gov', 100), ('workclass=Local-gov', 101), ('workclass=Never-worked', 102), ('workclass=Private', 103), ('workclass=Self-emp-inc', 104), ('workclass=Self-emp-not-inc', 105), ('workclass=State-gov', 106), ('workclass=Without-pay', 107)]\n"
     ]
    }
   ],
   "source": [
    "census_vec = sklearn.feature_extraction.DictVectorizer(sparse=False)\n",
    "census_vec.fit(census_train_csv)\n",
    "\n",
    "logprint(census_vec)\n",
    "\n",
    "randTest = {'marital-status': 'Married-civ-spouse', 'race': 'White', 'hours-per-week': 44, 'education': 'Assoc-acdm', 'education-num': 12, 'age': 46, 'capital-gain': 0, 'occupation': 'Craft-repair', 'fnlwgt': 155489, 'workclass': 'Private', 'relationship': 'Husband', 'sex': 'Male', 'capital-loss': 0, 'native-country': 'United-States'}\n",
    "otherTest = {'marital-status': 'Married-civ-spouse', 'race': 'White', 'hours-per-week': 40, 'education': 'Some-college', 'education-num': 10, 'age': 34, 'capital-gain': 0, 'occupation': 'Handlers-cleaners', 'fnlwgt': 207668, 'workclass': 'Private', 'relationship': 'Husband', 'sex': 'Male', 'capital-loss': 1887, 'native-country': 'United-States'}\n",
    "\n",
    "temp = census_vec.transform(randTest)\n",
    "\n",
    "print(temp)\n",
    "print(len(temp[0]))\n",
    "print(census_vec.transform(otherTest))\n",
    "\n",
    "census_features = census_vec.vocabulary_\n",
    "\n",
    "census_features = sorted(census_features.items(), key=operator.itemgetter(1))\n",
    "print(census_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
      "        sparse=False)\n",
      "[[ 28.   0.   0.   1.  13.   0.   2.   1.   0.   0.]]\n",
      "10\n",
      "[[  3.      0.      0.      1.     21.075   1.      3.      1.      0.      1.   ]]\n",
      "[('age', 0), ('embarked=C', 1), ('embarked=Q', 2), ('embarked=S', 3), ('fare', 4), ('parch', 5), ('pclass', 6), ('sex=female', 7), ('sex=male', 8), ('sibsp', 9)]\n"
     ]
    }
   ],
   "source": [
    "titanic_vec = sklearn.feature_extraction.DictVectorizer(sparse=False)\n",
    "titanic_vec.fit(titanic_train_imputed_data)\n",
    "\n",
    "print(titanic_vec)\n",
    "\n",
    "randTest = {'pclass': 2.0, 'age': 28.0, 'sibsp': 0.0, 'parch': 0.0, 'fare': 13.0, 'sex': 'female', 'embarked': 'S'}\n",
    "otherTest = {'pclass': 3.0, 'age': 3.0, 'sibsp': 1.0, 'parch': 1.0, 'fare': 21.074999999999999, 'sex': 'female', 'embarked': 'S'}\n",
    "temp = titanic_vec.transform(randTest)\n",
    "\n",
    "print(temp)\n",
    "print(len(temp[0]))\n",
    "print(titanic_vec.transform(otherTest))\n",
    "\n",
    "titanic_featrues = titanic_vec.vocabulary_\n",
    "\n",
    "titanic_featrues = sorted(titanic_featrues.items(), key=operator.itemgetter(1))\n",
    "print(titanic_featrues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.split_rule = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.label = None\n",
    "\n",
    "def nodeDecision(node, data):\n",
    "    if node.split_rule != None:\n",
    "        logprint(\"Feature \" + str(node.split_rule[0]) + \", split across: \" + str(node.split_rule[1]) + \n",
    "                 \", found \" + str(data[node.split_rule[0]]))\n",
    "        if data[node.split_rule[0]] > node.split_rule[1]:\n",
    "            #logprint(\"Moving to right...\")\n",
    "            return nodeDecision(node.right, data)\n",
    "        else:\n",
    "            #logprint(\"Moving to left...\")\n",
    "            return nodeDecision(node.left, data)\n",
    "    else:\n",
    "        logprint(\"Ended at the decision: \")\n",
    "        logprint(str(node.label))\n",
    "        return node.label\n",
    "    \n",
    "def printWholeTree(node, k = 0):\n",
    "    if node.split_rule != None:\n",
    "        logprint(\"Level \" + str(k) + \", feature \" + str(node.split_rule[0]) + \", split across: \" + str(node.split_rule[1]))\n",
    "        printWholeTree(node.left, k+1)\n",
    "        printWholeTree(node.right, k+1)\n",
    "    else:\n",
    "        logprint(\"Level \" + str(k) + \", ended at the decision: \")\n",
    "        logprint(str(node.label))\n",
    "        return node.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Where left and right are maps from labels -> frequencies\n",
    "def impurity(left, right):\n",
    "    leftEn = 0\n",
    "    rightEn = 0\n",
    "    leftLen = 0\n",
    "    rightLen = 0\n",
    "    \n",
    "    for k,v in left.items():\n",
    "        leftLen += v\n",
    "    for k,v in right.items():\n",
    "        rightLen += v\n",
    "    if leftLen > 0:\n",
    "        for k,v in left.items():\n",
    "            p_c = v / leftLen\n",
    "            if v == 0: continue\n",
    "            leftEn -= p_c * np.log2(p_c)\n",
    "    if rightLen > 0:\n",
    "        for k,v in right.items():\n",
    "            p_c = v / rightLen\n",
    "            if v == 0: continue\n",
    "            rightEn -= p_c * np.log2(p_c)\n",
    "\n",
    "    weightSum = leftLen * leftEn + rightLen * rightEn\n",
    "    return weightSum / (leftLen + rightLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 0.5)\n",
      "(2, 0.5)\n",
      "guess\n"
     ]
    }
   ],
   "source": [
    "# Return None if the data is essentially pure across \n",
    "def segmenter(data, labels, skipFeatures=[], checkAllSplits=False):\n",
    "    uniqueLabels = set(labels)\n",
    "    minBadness = 100000\n",
    "    maxLabelIndex = -1\n",
    "    maxLabelSplitDir = -1\n",
    "    \n",
    "    #TODO: Confirm type of data and figure out type of labels\n",
    "    \n",
    "    if len(labels) == 0:\n",
    "        return None\n",
    "    \n",
    "    firstLabel = labels[0]\n",
    "    pure = True\n",
    "    for label in labels:\n",
    "        if firstLabel != label:\n",
    "            pure = False\n",
    "            break\n",
    "    if pure:\n",
    "        return None\n",
    "    \n",
    "    featuresEqual = True\n",
    "    for featureIndex in range(len(data[0])):\n",
    "        if featureIndex in skipFeatures: continue\n",
    "        equalNum = data[0][featureIndex]\n",
    "        equal = True\n",
    "        for dataIndex in range(len(data)):\n",
    "            equal = equal and (equalNum == data[dataIndex][featureIndex]) \n",
    "        if not equal: \n",
    "            featuresEqual = False\n",
    "            break\n",
    "        featuresEqual = featuresEqual and equal\n",
    "    if featuresEqual:\n",
    "        return \"guess\"\n",
    "    \n",
    "    for featureIndex in range(len(data[0])):\n",
    "        #splits = [] #With binary variables, a 0 split \n",
    "                        #is equivalent to a 1 split \n",
    "        if featureIndex in skipFeatures:\n",
    "            continue\n",
    "            \n",
    "        splits = None    \n",
    "            \n",
    "        if not checkAllSplits:\n",
    "            minSplit = None\n",
    "            maxSplit = None\n",
    "            for dataIndex in range(len(data)):\n",
    "                if maxSplit == None or data[dataIndex][featureIndex] > maxSplit:\n",
    "                    maxSplit = data[dataIndex][featureIndex]\n",
    "                if minSplit == None or data[dataIndex][featureIndex] < minSplit:\n",
    "                    minSplit = data[dataIndex][featureIndex]\n",
    "            splits = [(minSplit + maxSplit) / 2.0] \n",
    "        else:\n",
    "            splits = []\n",
    "            for dataIndex in range(len(data)):\n",
    "                if data[dataIndex][featureIndex] not in splits:\n",
    "                    splits.append(data[dataIndex][featureIndex])\n",
    "                    splits.append(data[dataIndex][featureIndex] + 0.5)\n",
    "        \n",
    "        for split in splits:\n",
    "            \n",
    "            left = dict()\n",
    "            right = dict()\n",
    "            for uniqueLabel in uniqueLabels:\n",
    "                left[uniqueLabel] = 0\n",
    "                right[uniqueLabel] = 0\n",
    "            \n",
    "            \"\"\"\n",
    "            for dataIndex in range(len(data)):\n",
    "                if data[dataIndex][labelIndex] != split:\n",
    "                    for labelIndex2 in range(len(labels)):\n",
    "                        left[labelIndex2] += 1\n",
    "                else:\n",
    "                    for labelIndex2 in range(len(labels)):\n",
    "                        right[labelIndex2] += 1\n",
    "            \"\"\"\n",
    "            \n",
    "            for dataIndex in range(len(data)):\n",
    "                if data[dataIndex][featureIndex] <= split:\n",
    "                    left[labels[dataIndex]] += 1\n",
    "                else:\n",
    "                    right[labels[dataIndex]] += 1\n",
    "                    \n",
    "            badness = impurity(left, right)\n",
    "            \n",
    "            #print(str(featureIndex) + \" \" + str(split) + \" \" + str(badness))\n",
    "            #print(str(left[\"a\"]) + \" \" + str(left[\"b\"]))\n",
    "            #print(str(right[\"a\"]) + \" \" + str(right[\"b\"]))\n",
    "            #print(badness)\n",
    "            #print(\"----------\")\n",
    "            \n",
    "            \n",
    "            if badness < minBadness or maxLabelIndex == -1:\n",
    "                minBadness = badness\n",
    "                maxLabelIndex = featureIndex\n",
    "                maxLabelSplitDir = split\n",
    "                \n",
    "    \"\"\"\n",
    "    print(\"Min entropy: \" + str(minBadness))\n",
    "    if minBadness <= 0:\n",
    "        print(data)\n",
    "        print(str(maxLabelIndex) + \" \" + str(maxLabelSplitDir))\n",
    "        left = dict()\n",
    "        right = dict()\n",
    "        for uniqueLabel in uniqueLabels:\n",
    "            left[uniqueLabel] = 0\n",
    "            right[uniqueLabel] = 0\n",
    "        for dataIndex in range(len(data)):\n",
    "            print(data[dataIndex][maxLabelIndex])\n",
    "            if data[dataIndex][maxLabelIndex] <= maxLabelSplitDir:\n",
    "                left[labels[dataIndex]] += 1\n",
    "            else:\n",
    "                right[labels[dataIndex]] += 1\n",
    "        print(\":\")\n",
    "        print(left)\n",
    "        print(right)\n",
    "        print(\"----------\")\n",
    "    \"\"\"\n",
    "    \n",
    "    return (maxLabelIndex, maxLabelSplitDir)\n",
    "\n",
    "test = np.array([\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,0],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,0],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1]\n",
    "    ])\n",
    "print(segmenter(test, [\"a\",\"a\",\"b\",\"a\",\"b\",\"a\",\"b\",\"b\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\"]))\n",
    "\n",
    "test = np.array([\n",
    "        [1,1,0,1],\n",
    "        [1,0,1,1],\n",
    "        [0,1,1,1],\n",
    "        [1,1,1,0],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,1]\n",
    "    ])\n",
    "print(segmenter(test, [\"a\",\"a\",\"a\",\"a\",\"b\",\"b\",\"b\",\"b\"]))\n",
    "\n",
    "test = np.array([\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "    ])\n",
    "print(segmenter(test, [\"a\",\"a\",\"a\",\"b\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "#initialNode = Node()\n",
    "\n",
    "def train(node, data, labels, levels=3, randomForest=False, checkAllSplits=False):\n",
    "    logprint(\"---------------\")\n",
    "    \n",
    "    if len(labels) <= 0: return\n",
    "    \n",
    "    uniqueLabels = set(labels)\n",
    "    \n",
    "    if levels <= 0 or len(data) <= 3:\n",
    "        logprint(\"A guessing rule was found for data at the lowest depth or for a small number of nodes: \")\n",
    "        labelsByCount = dict()\n",
    "        for label in uniqueLabels:\n",
    "            labelsByCount[label] = 0\n",
    "        for label in labels:\n",
    "            labelsByCount[label] += 1\n",
    "        maxLabel = None\n",
    "        maxLabelScore = -1;\n",
    "        for label in uniqueLabels:\n",
    "            if labelsByCount[label] > maxLabelScore or maxLabel == None:\n",
    "                maxLabelScore = labelsByCount[label]\n",
    "                maxLabel = label\n",
    "        logprint('Decided on majority 1')\n",
    "        logprint(maxLabel)\n",
    "        logprint(labelsByCount)\n",
    "        node.label = maxLabel\n",
    "        return\n",
    "    \n",
    "    labelsByCount = dict()\n",
    "    for label in uniqueLabels:\n",
    "        labelsByCount[label] = 0\n",
    "    for label in labels:\n",
    "        labelsByCount[label] += 1\n",
    "    for label in uniqueLabels:\n",
    "        if labelsByCount[label] / len(labels) >= 0.9:\n",
    "            logprint('Decided on majority 2')\n",
    "            logprint(label)\n",
    "            logprint(labels)\n",
    "            node.label = label\n",
    "            return \n",
    "        \n",
    "    decision = None\n",
    "    if randomForest:\n",
    "        numFeatures = len(data[0])\n",
    "        #desiredLenSampleFeatures = int(math.ceil(math.sqrt(numFeatures)))\n",
    "        desiredLenSampleFeatures = int(numFeatures / 3.0)\n",
    "        sampleFeatures = []\n",
    "        while True: #randomly pick m of d features specified in note 16\n",
    "            randFeature = int(random.random() * numFeatures)\n",
    "            if randFeature not in sampleFeatures:\n",
    "                sampleFeatures.append(randFeature)\n",
    "            if len(sampleFeatures) >= desiredLenSampleFeatures:\n",
    "                break\n",
    "\n",
    "        skipFeatures = [i for i in range(numFeatures) if i not in sampleFeatures]    \n",
    "\n",
    "        decision = segmenter(data, labels, skipFeatures, checkAllSplits)\n",
    "    else:\n",
    "        decision = segmenter(data, labels, [], checkAllSplits)\n",
    "\n",
    "    \n",
    "    logprint(\"For data set: ...\")\n",
    "    #print(data)\n",
    "    logprint(\"and labels: \")\n",
    "    logprint(labels)\n",
    "\n",
    "    if decision != None: #A split rule was found for a non-pure node\n",
    "        if decision == \"guess\": #It's a decision for non-separable data: \n",
    "            uniqueLabels = set(labels)\n",
    "            logprint(\"A guessing rule was found for non-separable data: \")\n",
    "            labelsByCount = dict()\n",
    "            for label in uniqueLabels:\n",
    "                labelsByCount[label] = 0\n",
    "            for label in labels:\n",
    "                labelsByCount[label] += 1\n",
    "            maxLabel = None\n",
    "            maxLabelScore = -1;\n",
    "            for label in uniqueLabels:\n",
    "                if labelsByCount[label] > maxLabelScore or maxLabel == None:\n",
    "                    maxLabelScore = labelsByCount[label]\n",
    "                    maxLabel = label\n",
    "            logprint('Decided on guessing:')\n",
    "            logprint(maxLabel)\n",
    "            node.label = maxLabel\n",
    "        else:\n",
    "            logprint(\"A decision rule was found: \")\n",
    "            logprint(decision)\n",
    "            node.split_rule = decision\n",
    "            node.left = Node()\n",
    "            node.right = Node()\n",
    "            leftData = []\n",
    "            rightData = []\n",
    "            leftLabels = []\n",
    "            rightLabels = []\n",
    "            for dataIndex in range(len(data)):\n",
    "                if data[dataIndex][decision[0]] > decision[1]:\n",
    "                    rightData.append(data[dataIndex])\n",
    "                    rightLabels.append(labels[dataIndex])\n",
    "                else:\n",
    "                    leftData.append(data[dataIndex])\n",
    "                    leftLabels.append(labels[dataIndex])\n",
    "            logprint(str(len(leftData)) + \" \" + str(len(rightData)))\n",
    "            leftData = np.array(leftData)\n",
    "            rightData = np.array(rightData)\n",
    "            train(node.left, leftData, leftLabels, levels - 1)\n",
    "            train(node.right, rightData, rightLabels, levels - 1)\n",
    "    else:\n",
    "        logprint(\"No decision was found for a pure node\")\n",
    "        #if len(labels) == 0: return\n",
    "        print('Decided on pure:')\n",
    "        print(labels[0])\n",
    "        node.label = labels[0]\n",
    "    \n",
    "def fullTrain(data, labels, levels=3, randomForest=False, checkAllSplits=False):\n",
    "    initialNode = Node()\n",
    "    train(initialNode, data, labels, levels, randomForest)\n",
    "    return initialNode\n",
    "    \n",
    "testData = np.array([\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,0],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,0],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,1,1],\n",
    "        [0,0,0,0]\n",
    "    ])\n",
    "testLabels = np.array(\n",
    "    [\"a\",\"a\",\"b\",\"a\",\"b\",\"a\",\"b\",\"b\",\"b\",\"a\",\"a\",\"b\",\"a\",\"a\",\"c\"]\n",
    ")\n",
    "\n",
    "initialNode = fullTrain(testData, testLabels, 5)\n",
    "\n",
    "print(nodeDecision(initialNode, [0,0,0,0]))\n",
    "print(nodeDecision(initialNode, [1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def randomForestTrain(data, labels, levels = 15, trees = 10): \n",
    "    randomForestRoots = []\n",
    "    for indexTree in range(trees):\n",
    "        print(indexTree)\n",
    "        \n",
    "        copyData = np.array(data)\n",
    "        #for featureIndex in range(numFeatures):\n",
    "            #if featureIndex not in sampleFeatures:\n",
    "                #for dataIndex in range(len(data)):\n",
    "                    #copyData[dataIndex][featureIndex] = 0\n",
    "        \n",
    "        indices = [i for i in range(len(data))]\n",
    "        chosenIndices = []\n",
    "        for i in range(int(len(data) * 0.4)):\n",
    "            randIndex = int(random.random() * len(indices)) \n",
    "            chosenIndices.append(indices.pop(randIndex))\n",
    "        \n",
    "        copyDataSubset = []\n",
    "        copyLabels = []\n",
    "        for chosen in chosenIndices:\n",
    "            copyDataSubset.append(copyData[chosen])\n",
    "            copyLabels.append(labels[chosen])\n",
    "        copyDataSubset = np.array(copyDataSubset)\n",
    "        \n",
    "        \"\"\"\n",
    "        print(copyDataSubset)\n",
    "        print(copyLabels)\n",
    "        print(copyDataSubset[0])\n",
    "        print(\"------\")\n",
    "        \"\"\"\n",
    "        \n",
    "        treeRoot = fullTrain(copyDataSubset, copyLabels, levels, True, False)\n",
    "        \n",
    "        randomForestRoots.append(treeRoot)\n",
    "    return randomForestRoots\n",
    "\n",
    "def randomForestDecide(randomForestRoots, decisionPoint):\n",
    "    candidates = dict()\n",
    "    for forestRoot in randomForestRoots:\n",
    "        prediction = nodeDecision(forestRoot, decisionPoint)\n",
    "        if prediction not in candidates:\n",
    "            candidates[prediction] = 0\n",
    "        candidates[prediction] += 1\n",
    "    maxLabel = None\n",
    "    maxLabelValue = -1\n",
    "    for k,v in candidates.items():\n",
    "        if maxLabel == None or v > maxLabelValue:\n",
    "            maxLabel = k\n",
    "            maxLabelValue = v\n",
    "    logprint(candidates)\n",
    "    logprint(maxLabel)\n",
    "    return maxLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[50, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "listy = [1,2,3]\n",
    "nparr = list(listy)\n",
    "nparr[0] = 50;\n",
    "print(listy)\n",
    "print(nparr)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 2.0\n",
      "Feature 6, split across: 1.5, found 2.0\n",
      "Ended at the decision: \n",
      "0.0\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Feature 6, split across: 1.5, found 1.0\n",
      "Ended at the decision: \n",
      "0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Feature 6, split across: 1.5, found 1.0\n",
      "Ended at the decision: \n",
      "0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Feature 6, split across: 1.5, found 1.0\n",
      "Ended at the decision: \n",
      "0.0\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 3.0\n",
      "Feature 4, split across: 34.775, found 8.05\n",
      "Ended at the decision: \n",
      "0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 3.0\n",
      "Feature 4, split across: 34.775, found 7.225\n",
      "Ended at the decision: \n",
      "0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Feature 6, split across: 1.5, found 1.0\n",
      "Ended at the decision: \n",
      "0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 3.0\n",
      "Feature 4, split across: 34.775, found 7.8958\n",
      "Ended at the decision: \n",
      "0.0\n",
      "0.797979797979798\n",
      "Level 0, feature 7, split across: 0.5\n",
      "Level 1, feature 6, split across: 2.0\n",
      "Level 2, feature 6, split across: 1.5\n",
      "Level 3, ended at the decision: \n",
      "0.0\n",
      "Level 3, ended at the decision: \n",
      "0.0\n",
      "Level 2, feature 4, split across: 34.775\n",
      "Level 3, ended at the decision: \n",
      "0.0\n",
      "Level 3, ended at the decision: \n",
      "0.0\n",
      "Level 1, feature 6, split across: 2.0\n",
      "Level 2, ended at the decision: \n",
      "1.0\n",
      "Level 2, feature 3, split across: 0.5\n",
      "Level 3, ended at the decision: \n",
      "1.0\n",
      "Level 3, ended at the decision: \n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Titanic Training/Validation Regular\n",
    "\n",
    "indices = [i for i in range(len(titanic_train_imputed_data))]\n",
    "random.shuffle(indices)\n",
    "\n",
    "copyData = []\n",
    "copyLabels = []\n",
    "\n",
    "validationData = []\n",
    "validationLabels = []\n",
    "\n",
    "for i in range(900):\n",
    "    copyData.append(titanic_train_imputed_data[indices[i]])\n",
    "    copyLabels.append(titanic_train_labels[indices[i]])\n",
    "for i in range(900,999):\n",
    "    validationData.append(titanic_train_imputed_data[indices[i]])\n",
    "    validationLabels.append(titanic_train_labels[indices[i]])\n",
    "    \n",
    "#-------------------------\n",
    "\n",
    "trainingSetTransformed = titanic_vec.transform(copyData)\n",
    "validSetTransformed = titanic_vec.transform(validationData)\n",
    "\n",
    "trainedTitanicNode = fullTrain(trainingSetTransformed, copyLabels, 3)\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "logging = True\n",
    "\n",
    "for i in range(len(validSetTransformed)):\n",
    "    if i >= 10: logging = False\n",
    "    transformed = validSetTransformed[i]\n",
    "    prediction = nodeDecision(trainedTitanicNode, transformed)\n",
    "    #print(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "    if str(prediction) == str(validationLabels[i]):\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy /= len(validationLabels)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "#-------------------------\n",
    "\n",
    "testSetTransformed = titanic_vec.transform(titanic_test_csv)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(len(testSetTransformed)):\n",
    "    if i >= 10: logging = False\n",
    "    transformed = testSetTransformed[i]\n",
    "    prediction = nodeDecision(trainedTitanicNode, transformed)\n",
    "    #print(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "    results.append([i+1, int(prediction)])\n",
    "    \n",
    "temp = np.asarray(results)\n",
    "#temp.tofile(\"./submission.py\")\n",
    "np.savetxt(\"titanic_submission.csv\", temp, fmt=\"%i,%i\", delimiter=\",\", header=\"Id,Category\")\n",
    "\n",
    "#-------\n",
    "\n",
    "logging = True\n",
    "printWholeTree(trainedTitanicNode)\n",
    "logging = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 4, split across: 256.1646, found 26.55\n",
      "Moving to left...\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 1, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Moving to left...\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 0, split across: 30.5, found 21.0\n",
      "Moving to left...\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Feature 1, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 0, split across: 15.5, found 21.0\n",
      "Moving to right...\n",
      "Feature 0, split across: 24.0, found 21.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 1, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 7, split across: 0.5, found 1.0\n",
      "Moving to right...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Moving to left...\n",
      "Feature 6, split across: 2.0, found 1.0\n",
      "Moving to left...\n",
      "Ended at the decision: \n",
      "1.0\n",
      "{1.0: 25}\n",
      "1.0\n",
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "#Titanic Train/Validation Random Forest\n",
    "\n",
    "forestRoots = randomForestTrain(trainingSetTransformed, copyLabels, 15, 25)\n",
    "\n",
    "logging = True\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(len(validSetTransformed)):\n",
    "    if i >= 1: logging = False\n",
    "    transformed = validSetTransformed[i]\n",
    "    #prediction = nodeDecision(trainedCensusNode, transformed)\n",
    "    prediction = randomForestDecide(forestRoots, transformed)\n",
    "    #print(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "    if str(prediction) == str(validationLabels[i]):\n",
    "        accuracy += 1\n",
    "        \n",
    "accuracy /= len(validationLabels)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 14.0, found 0.0\n",
      "Feature 19, split across: 7.0, found 0.0\n",
      "Feature 19, split across: 3.5, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 44.0, found 4.0\n",
      "Feature 20, split across: 2.5, found 0.0\n",
      "Feature 20, split across: 1.0, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 33.0, found 0.0\n",
      "Feature 14, split across: 16.5, found 0.0\n",
      "Feature 3, split across: 9.5, found 0.0\n",
      "Feature 3, split across: 4.5, found 0.0\n",
      "Feature 3, split across: 2.0, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 7.5, found 0.0\n",
      "Feature 5, split across: 3.5, found 0.0\n",
      "Feature 5, split across: 1.5, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 7.0, found 0.0\n",
      "Feature 15, split across: 3.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 5.0, found 0.0\n",
      "Feature 12, split across: 2.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 16, split across: 4.0, found 0.0\n",
      "Feature 16, split across: 2.0, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 21.5, found 4.0\n",
      "Feature 28, split across: 10.5, found 4.0\n",
      "Feature 28, split across: 5.0, found 4.0\n",
      "Feature 28, split across: 2.5, found 4.0\n",
      "Feature 31, split across: 5.0, found 0.0\n",
      "Feature 12, split across: 1.0, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 1.0, found 2.0\n",
      "Ended at the decision: \n",
      "1\n",
      "1 1\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 14.0, found 1.0\n",
      "Feature 19, split across: 7.0, found 1.0\n",
      "Feature 19, split across: 3.5, found 1.0\n",
      "Feature 19, split across: 1.5, found 1.0\n",
      "Feature 19, split across: 0.5, found 1.0\n",
      "Ended at the decision: \n",
      "0\n",
      "0 0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 14.0, found 0.0\n",
      "Feature 19, split across: 7.0, found 0.0\n",
      "Feature 19, split across: 3.5, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 44.0, found 0.0\n",
      "Feature 20, split across: 2.5, found 0.0\n",
      "Feature 20, split across: 1.0, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 33.0, found 0.0\n",
      "Feature 14, split across: 16.5, found 0.0\n",
      "Feature 3, split across: 9.5, found 0.0\n",
      "Feature 3, split across: 4.5, found 0.0\n",
      "Feature 3, split across: 2.0, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 7.5, found 0.0\n",
      "Feature 5, split across: 3.5, found 0.0\n",
      "Feature 5, split across: 1.5, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 7.0, found 0.0\n",
      "Feature 15, split across: 3.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 5.0, found 0.0\n",
      "Feature 12, split across: 2.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 16, split across: 4.0, found 0.0\n",
      "Feature 16, split across: 2.0, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 21.5, found 0.0\n",
      "Feature 28, split across: 10.5, found 0.0\n",
      "Feature 28, split across: 5.0, found 0.0\n",
      "Feature 28, split across: 2.5, found 0.0\n",
      "Feature 28, split across: 1.0, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 3.5, found 0.0\n",
      "Feature 14, split across: 1.5, found 0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "0 0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 14.0, found 0.0\n",
      "Feature 19, split across: 7.0, found 0.0\n",
      "Feature 19, split across: 3.5, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 44.0, found 1.0\n",
      "Feature 20, split across: 2.5, found 0.0\n",
      "Feature 20, split across: 1.0, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 33.0, found 0.0\n",
      "Feature 14, split across: 16.5, found 0.0\n",
      "Feature 3, split across: 9.5, found 0.0\n",
      "Feature 3, split across: 4.5, found 0.0\n",
      "Feature 3, split across: 2.0, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 7.5, found 0.0\n",
      "Feature 5, split across: 3.5, found 0.0\n",
      "Feature 5, split across: 1.5, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 7.0, found 0.0\n",
      "Feature 15, split across: 3.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 5.0, found 1.0\n",
      "Feature 12, split across: 2.5, found 1.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 16, split across: 4.0, found 0.0\n",
      "Feature 16, split across: 2.0, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 21.5, found 1.0\n",
      "Feature 28, split across: 10.5, found 1.0\n",
      "Feature 28, split across: 5.0, found 1.0\n",
      "Feature 28, split across: 2.5, found 1.0\n",
      "Feature 28, split across: 1.0, found 1.0\n",
      "Feature 28, split across: 0.5, found 1.0\n",
      "Feature 14, split across: 3.5, found 0.0\n",
      "Feature 29, split across: 18.5, found 0.0\n",
      "Feature 13, split across: 11.0, found 0.0\n",
      "Feature 24, split across: 3.5, found 0.0\n",
      "Feature 14, split across: 1.5, found 0.0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 3.5, found 1.0\n",
      "Ended at the decision: \n",
      "1\n",
      "1 1\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 14.0, found 0.0\n",
      "Feature 19, split across: 7.0, found 0.0\n",
      "Feature 19, split across: 3.5, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 44.0, found 1.0\n",
      "Feature 20, split across: 2.5, found 0.0\n",
      "Feature 20, split across: 1.0, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 33.0, found 0.0\n",
      "Feature 14, split across: 16.5, found 0.0\n",
      "Feature 3, split across: 9.5, found 0.0\n",
      "Feature 3, split across: 4.5, found 0.0\n",
      "Feature 3, split across: 2.0, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 7.5, found 0.0\n",
      "Feature 5, split across: 3.5, found 0.0\n",
      "Feature 5, split across: 1.5, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 7.0, found 0.0\n",
      "Feature 15, split across: 3.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 5.0, found 0.0\n",
      "Feature 12, split across: 2.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 16, split across: 4.0, found 0.0\n",
      "Feature 16, split across: 2.0, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 21.5, found 1.0\n",
      "Feature 28, split across: 10.5, found 1.0\n",
      "Feature 28, split across: 5.0, found 1.0\n",
      "Feature 28, split across: 2.5, found 1.0\n",
      "Feature 28, split across: 1.0, found 1.0\n",
      "Feature 28, split across: 0.5, found 1.0\n",
      "Feature 14, split across: 3.5, found 0.0\n",
      "Feature 29, split across: 18.5, found 0.0\n",
      "Feature 13, split across: 11.0, found 0.0\n",
      "Feature 24, split across: 3.5, found 0.0\n",
      "Feature 14, split across: 1.5, found 0.0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 3.5, found 0.0\n",
      "Ended at the decision: \n",
      "1\n",
      "1 1\n",
      "0.77\n"
     ]
    }
   ],
   "source": [
    "#Spam Training/Validation Regular\n",
    "\n",
    "indices = [i for i in range(len(spam_train_data))]\n",
    "random.shuffle(indices)\n",
    "\n",
    "copyData = []\n",
    "copyLabels = []\n",
    "\n",
    "validationData = []\n",
    "validationLabels = []\n",
    "\n",
    "for i in range(23000):\n",
    "    copyData.append(spam_train_data[indices[i]])\n",
    "    copyLabels.append(spam_train_labels[indices[i]])\n",
    "for i in range(22000,23000):\n",
    "    validationData.append(spam_train_data[indices[i]])\n",
    "    validationLabels.append(spam_train_labels[indices[i]])\n",
    "    \n",
    "trainedSpamNode = fullTrain(copyData, copyLabels, 30, False, False)\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "logging = True\n",
    "for i in range(len(validationData)):\n",
    "    if i >= 5: logging = False\n",
    "    transformed = validationData[i]\n",
    "    prediction = nodeDecision(trainedSpamNode, transformed)\n",
    "    logprint(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "    if str(prediction) == str(validationLabels[i]):\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy /= len(validationLabels)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(len(spam_test_data)):\n",
    "    if i >= 10: logging = False\n",
    "    transformed = spam_test_data[i]\n",
    "    prediction = nodeDecision(trainedSpamNode, transformed)\n",
    "    #print(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "    results.append([i, int(prediction)])\n",
    "    \n",
    "temp = np.asarray(results)\n",
    "#temp.tofile(\"./submission.py\")\n",
    "np.savetxt(\"spam_submission.csv\", temp, fmt=\"%i,%i\", delimiter=\",\", header=\"Id,Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 40.0, found 0.0\n",
      "Feature 3, split across: 7.0, found 0.0\n",
      "Feature 3, split across: 3.5, found 0.0\n",
      "Feature 3, split across: 1.5, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 7.0, found 0.0\n",
      "Feature 28, split across: 25.0, found 0.0\n",
      "Feature 12, split across: 5.0, found 0.0\n",
      "Feature 12, split across: 2.5, found 0.0\n",
      "Feature 28, split across: 12.5, found 0.0\n",
      "Feature 28, split across: 6.0, found 0.0\n",
      "Feature 28, split across: 3.0, found 0.0\n",
      "Feature 28, split across: 1.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 3.5, found 0.0\n",
      "Feature 21, split across: 1.5, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 3.5, found 0.0\n",
      "Feature 14, split across: 1.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 1, split across: 1.0, found 0.0\n",
      "Feature 1, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 13, split across: 6.5, found 0.0\n",
      "Feature 13, split across: 3.0, found 0.0\n",
      "Feature 13, split across: 1.5, found 0.0\n",
      "Feature 13, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 27, split across: 7.0, found 0.0\n",
      "Feature 27, split across: 3.0, found 0.0\n",
      "Feature 27, split across: 1.5, found 0.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Feature 22, split across: 0.5, found 0.0\n",
      "Feature 18, split across: 1.0, found 0.0\n",
      "Feature 19, split across: 6.0, found 0.0\n",
      "Feature 19, split across: 3.0, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 11.0, found 0.0\n",
      "Feature 9, split across: 1.0, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 6.5, found 0.0\n",
      "Feature 2, split across: 3.0, found 0.0\n",
      "Feature 2, split across: 1.5, found 0.0\n",
      "Feature 2, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 41.0, found 0.0\n",
      "Feature 19, split across: 13.5, found 0.0\n",
      "Feature 19, split across: 6.5, found 0.0\n",
      "Feature 19, split across: 3.0, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 13, split across: 22.5, found 0.0\n",
      "Feature 13, split across: 11.0, found 0.0\n",
      "Feature 13, split across: 5.5, found 0.0\n",
      "Feature 13, split across: 2.5, found 0.0\n",
      "Feature 13, split across: 1.0, found 0.0\n",
      "Feature 13, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 7.0, found 0.0\n",
      "Feature 3, split across: 3.5, found 0.0\n",
      "Feature 3, split across: 1.5, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 6.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 31, split across: 18.0, found 0.0\n",
      "Feature 31, split across: 9.0, found 0.0\n",
      "Feature 31, split across: 4.0, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 5, split across: 2.5, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 17, split across: 1.5, found 0.0\n",
      "Feature 17, split across: 0.5, found 0.0\n",
      "Feature 27, split across: 14.0, found 0.0\n",
      "Feature 21, split across: 2.5, found 0.0\n",
      "Feature 21, split across: 1.0, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 27, split across: 5.0, found 0.0\n",
      "Ended at the decision: \n",
      "1\n",
      "Feature 31, split across: 33.5, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 10.5, found 0.0\n",
      "Feature 2, split across: 6.5, found 0.0\n",
      "Feature 2, split across: 3.0, found 0.0\n",
      "Feature 19, split across: 12.0, found 0.0\n",
      "Feature 19, split across: 5.5, found 0.0\n",
      "Feature 19, split across: 2.5, found 0.0\n",
      "Feature 19, split across: 1.0, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 16, split across: 3.0, found 0.0\n",
      "Feature 16, split across: 1.5, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 1.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 15.5, found 0.0\n",
      "Feature 31, split across: 7.5, found 0.0\n",
      "Feature 31, split across: 3.5, found 0.0\n",
      "Feature 31, split across: 1.5, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 25.0, found 0.0\n",
      "Feature 28, split across: 12.5, found 0.0\n",
      "Feature 28, split across: 6.0, found 0.0\n",
      "Feature 28, split across: 3.0, found 0.0\n",
      "Feature 28, split across: 1.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 5.0, found 0.0\n",
      "Feature 3, split across: 2.5, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.0, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 4.5, found 0.0\n",
      "Feature 12, split across: 2.0, found 0.0\n",
      "Feature 14, split across: 6.0, found 0.0\n",
      "Feature 27, split across: 6.0, found 0.0\n",
      "Feature 13, split across: 8.0, found 0.0\n",
      "Feature 7, split across: 1.0, found 0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 1.0, found 0.0\n",
      "Feature 8, split across: 3.5, found 0.0\n",
      "Feature 11, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 7.5, found 0.0\n",
      "Feature 15, split across: 3.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 26, split across: 101.0, found 0.0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 30.0, found 0.0\n",
      "Feature 28, split across: 15.0, found 0.0\n",
      "Feature 28, split across: 7.5, found 0.0\n",
      "Feature 28, split across: 3.5, found 0.0\n",
      "Feature 28, split across: 1.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 14, split across: 10.5, found 0.0\n",
      "Feature 2, split across: 6.0, found 0.0\n",
      "Feature 2, split across: 3.0, found 0.0\n",
      "Feature 2, split across: 1.5, found 0.0\n",
      "Feature 3, split across: 5.0, found 0.0\n",
      "Feature 3, split across: 2.5, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 3.5, found 0.0\n",
      "Feature 12, split across: 1.5, found 0.0\n",
      "Feature 12, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 5.0, found 0.0\n",
      "Feature 7, split across: 1.0, found 0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 11, split across: 8.0, found 0.0\n",
      "Feature 8, split across: 1.0, found 0.0\n",
      "Feature 11, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 0.5, found 0.0\n",
      "Feature 18, split across: 2.0, found 0.0\n",
      "Feature 18, split across: 1.0, found 0.0\n",
      "Feature 18, split across: 0.5, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 2.5, found 0.0\n",
      "Feature 14, split across: 1.0, found 0.0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 6.5, found 0.0\n",
      "Feature 19, split across: 3.0, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 1.0, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 4.0, found 0.0\n",
      "Feature 20, split across: 2.5, found 0.0\n",
      "Feature 20, split across: 1.0, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 14.0, found 0.0\n",
      "Feature 19, split across: 7.0, found 0.0\n",
      "Feature 19, split across: 3.5, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 56.0, found 0.0\n",
      "Feature 29, split across: 28.0, found 0.0\n",
      "Feature 3, split across: 8.5, found 0.0\n",
      "Feature 3, split across: 4.0, found 0.0\n",
      "Feature 3, split across: 2.0, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 13.5, found 0.0\n",
      "Feature 29, split across: 6.5, found 0.0\n",
      "Feature 29, split across: 3.0, found 0.0\n",
      "Feature 29, split across: 1.5, found 0.0\n",
      "Feature 29, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 22.5, found 0.0\n",
      "Feature 28, split across: 10.5, found 0.0\n",
      "Feature 28, split across: 5.0, found 0.0\n",
      "Feature 28, split across: 2.5, found 0.0\n",
      "Feature 28, split across: 1.0, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 4.0, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 1.5, found 0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 23, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 3.5, found 0.0\n",
      "Feature 2, split across: 1.5, found 0.0\n",
      "Feature 1, split across: 1.5, found 0.0\n",
      "Feature 1, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 1.0, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 11, split across: 5.5, found 0.0\n",
      "Feature 27, split across: 6.0, found 0.0\n",
      "Feature 27, split across: 3.0, found 0.0\n",
      "Feature 27, split across: 1.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 56.0, found 0.0\n",
      "Feature 29, split across: 28.0, found 0.0\n",
      "Feature 3, split across: 9.5, found 0.0\n",
      "Feature 3, split across: 4.5, found 0.0\n",
      "Feature 3, split across: 2.0, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 14.0, found 0.0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 7.0, found 0.0\n",
      "Feature 29, split across: 3.5, found 0.0\n",
      "Feature 29, split across: 1.5, found 0.0\n",
      "Feature 29, split across: 0.5, found 0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 22.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 6.0, found 0.0\n",
      "Feature 19, split across: 3.0, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 4.0, found 0.0\n",
      "Feature 16, split across: 3.0, found 0.0\n",
      "Feature 16, split across: 1.5, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 5, split across: 2.5, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 18, split across: 2.5, found 0.0\n",
      "Feature 26, split across: 21.5, found 0.0\n",
      "Feature 26, split across: 9.5, found 0.0\n",
      "Feature 26, split across: 4.5, found 0.0\n",
      "Feature 15, split across: 2.5, found 0.0\n",
      "Feature 26, split across: 2.0, found 0.0\n",
      "Feature 26, split across: 1.0, found 0.0\n",
      "Feature 26, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 3.0, found 0.0\n",
      "Feature 17, split across: 1.0, found 0.0\n",
      "Feature 17, split across: 0.5, found 0.0\n",
      "Feature 22, split across: 1.0, found 0.0\n",
      "Feature 22, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 33.0, found 0.0\n",
      "Feature 21, split across: 1.0, found 0.0\n",
      "Ended at the decision: \n",
      "1\n",
      "Feature 0, split across: 3.5, found 0.0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 27.5, found 0.0\n",
      "Feature 31, split across: 13.5, found 0.0\n",
      "Feature 31, split across: 6.5, found 0.0\n",
      "Feature 31, split across: 3.0, found 0.0\n",
      "Feature 31, split across: 1.5, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 7.0, found 0.0\n",
      "Feature 3, split across: 3.5, found 0.0\n",
      "Feature 3, split across: 1.5, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 1.5, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 1.5, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 5.0, found 0.0\n",
      "Feature 5, split across: 3.0, found 0.0\n",
      "Feature 5, split across: 1.5, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 7.5, found 0.0\n",
      "Feature 15, split across: 3.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 27, split across: 17.0, found 0.0\n",
      "Feature 19, split across: 10.0, found 0.0\n",
      "Feature 19, split across: 5.0, found 0.0\n",
      "Feature 19, split across: 2.5, found 0.0\n",
      "Feature 19, split across: 1.0, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 17, split across: 1.5, found 0.0\n",
      "Feature 17, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 25.0, found 0.0\n",
      "Feature 28, split across: 12.0, found 0.0\n",
      "Feature 28, split across: 6.0, found 0.0\n",
      "Feature 28, split across: 3.0, found 0.0\n",
      "Feature 28, split across: 1.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 3.5, found 0.0\n",
      "Feature 30, split across: 1.5, found 0.0\n",
      "Feature 30, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 27, split across: 6.0, found 0.0\n",
      "Feature 14, split across: 5.5, found 0.0\n",
      "Feature 8, split across: 3.5, found 0.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 31, split across: 42.0, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 19.0, found 0.0\n",
      "Feature 0, split across: 1.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 27.5, found 0.0\n",
      "Feature 28, split across: 13.5, found 0.0\n",
      "Feature 28, split across: 6.5, found 0.0\n",
      "Feature 28, split across: 3.0, found 0.0\n",
      "Feature 28, split across: 1.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 6.0, found 0.0\n",
      "Feature 3, split across: 3.0, found 0.0\n",
      "Feature 3, split across: 1.5, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 9.0, found 0.0\n",
      "Feature 31, split across: 4.5, found 0.0\n",
      "Feature 31, split across: 2.0, found 0.0\n",
      "Feature 31, split across: 1.0, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 22, split across: 1.5, found 0.0\n",
      "Feature 27, split across: 6.0, found 0.0\n",
      "Feature 19, split across: 6.5, found 0.0\n",
      "Feature 19, split across: 3.0, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 16, split across: 2.5, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 4.5, found 0.0\n",
      "Feature 30, split across: 5.5, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 5.0, found 0.0\n",
      "Feature 15, split across: 2.5, found 0.0\n",
      "Feature 15, split across: 1.0, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 1.5, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 5.5, found 0.0\n",
      "Feature 14, split across: 2.5, found 0.0\n",
      "Feature 14, split across: 1.0, found 0.0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 26, split across: 33.0, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 42.0, found 0.0\n",
      "Feature 31, split across: 21.0, found 0.0\n",
      "Feature 3, split across: 9.5, found 0.0\n",
      "Feature 3, split across: 4.5, found 0.0\n",
      "Feature 3, split across: 2.0, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 22.5, found 0.0\n",
      "Feature 28, split across: 10.5, found 0.0\n",
      "Feature 28, split across: 5.0, found 0.0\n",
      "Feature 28, split across: 2.5, found 0.0\n",
      "Feature 28, split across: 1.0, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 9.0, found 0.0\n",
      "Feature 31, split across: 4.5, found 0.0\n",
      "Feature 31, split across: 2.0, found 0.0\n",
      "Feature 31, split across: 1.0, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 27, split across: 6.5, found 0.0\n",
      "Feature 19, split across: 5.5, found 0.0\n",
      "Feature 19, split across: 2.5, found 0.0\n",
      "Feature 19, split across: 1.0, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 16, split across: 2.5, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 4.0, found 0.0\n",
      "Feature 12, split across: 2.0, found 0.0\n",
      "Feature 22, split across: 1.0, found 0.0\n",
      "Feature 22, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 1.5, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 1.0, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 6.0, found 0.0\n",
      "Feature 17, split across: 2.0, found 0.0\n",
      "Feature 17, split across: 1.0, found 0.0\n",
      "Feature 17, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 33.5, found 0.0\n",
      "Feature 12, split across: 10.5, found 0.0\n",
      "Feature 16, split across: 4.5, found 0.0\n",
      "Feature 16, split across: 2.0, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 6.0, found 0.0\n",
      "Feature 2, split across: 3.0, found 0.0\n",
      "Feature 2, split across: 1.5, found 0.0\n",
      "Feature 2, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 7.5, found 0.0\n",
      "Feature 0, split across: 2.0, found 0.0\n",
      "Feature 0, split across: 1.0, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 15.5, found 0.0\n",
      "Feature 31, split across: 7.5, found 0.0\n",
      "Feature 31, split across: 3.5, found 0.0\n",
      "Feature 31, split across: 1.5, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 1.5, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 22.5, found 0.0\n",
      "Feature 28, split across: 11.0, found 0.0\n",
      "Feature 28, split across: 5.5, found 0.0\n",
      "Feature 28, split across: 2.5, found 0.0\n",
      "Feature 28, split across: 1.0, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 5.0, found 0.0\n",
      "Feature 3, split across: 2.5, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 6.5, found 0.0\n",
      "Feature 19, split across: 3.0, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 13, split across: 8.0, found 0.0\n",
      "Feature 27, split across: 6.0, found 0.0\n",
      "Feature 12, split across: 4.0, found 0.0\n",
      "Feature 12, split across: 2.0, found 0.0\n",
      "Feature 24, split across: 4.0, found 0.0\n",
      "Feature 4, split across: 1.0, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 20, split across: 1.5, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 26, split across: 89.5, found 0.0\n",
      "Feature 31, split across: 24.0, found 0.0\n",
      "Feature 31, split across: 11.0, found 0.0\n",
      "Feature 31, split across: 5.5, found 0.0\n",
      "Feature 2, split across: 6.0, found 0.0\n",
      "Feature 2, split across: 3.0, found 0.0\n",
      "Feature 2, split across: 1.5, found 0.0\n",
      "Feature 31, split across: 2.5, found 0.0\n",
      "Feature 31, split across: 1.0, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 28.0, found 0.0\n",
      "Feature 26, split across: 33.0, found 0.0\n",
      "Feature 12, split across: 5.0, found 0.0\n",
      "Feature 3, split across: 7.0, found 0.0\n",
      "Feature 3, split across: 3.5, found 0.0\n",
      "Feature 3, split across: 1.5, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 25.0, found 0.0\n",
      "Feature 28, split across: 12.5, found 0.0\n",
      "Feature 28, split across: 6.0, found 0.0\n",
      "Feature 28, split across: 3.0, found 0.0\n",
      "Feature 28, split across: 1.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 1.5, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 13.0, found 0.0\n",
      "Feature 27, split across: 6.0, found 0.0\n",
      "Feature 24, split across: 2.5, found 0.0\n",
      "Feature 27, split across: 3.0, found 0.0\n",
      "Feature 27, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 3.5, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 22, split across: 1.0, found 0.0\n",
      "Feature 29, split across: 6.5, found 0.0\n",
      "Feature 29, split across: 3.0, found 0.0\n",
      "Feature 29, split across: 1.5, found 0.0\n",
      "Feature 29, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 3.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 1.0, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 45.5, found 0.0\n",
      "Feature 3, split across: 7.0, found 0.0\n",
      "Feature 3, split across: 3.5, found 0.0\n",
      "Feature 3, split across: 1.5, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 5, split across: 3.5, found 0.0\n",
      "Feature 5, split across: 1.5, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 5.0, found 0.0\n",
      "Feature 28, split across: 25.0, found 0.0\n",
      "Feature 21, split across: 1.5, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 12, split across: 2.5, found 0.0\n",
      "Feature 29, split across: 21.0, found 0.0\n",
      "Feature 12, split across: 1.0, found 0.0\n",
      "Feature 12, split across: 0.5, found 0.0\n",
      "Feature 16, split across: 3.5, found 0.0\n",
      "Feature 16, split across: 1.5, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 4.5, found 0.0\n",
      "Feature 27, split across: 17.0, found 0.0\n",
      "Feature 19, split across: 8.5, found 0.0\n",
      "Feature 19, split across: 4.0, found 0.0\n",
      "Feature 19, split across: 2.0, found 0.0\n",
      "Feature 19, split across: 1.0, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 7, split across: 1.0, found 0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 12.0, found 0.0\n",
      "Feature 28, split across: 6.0, found 0.0\n",
      "Feature 28, split across: 3.0, found 0.0\n",
      "Feature 28, split across: 1.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 3.0, found 0.0\n",
      "Feature 27, split across: 6.0, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 1.0, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 16, split across: 4.5, found 0.0\n",
      "Feature 16, split across: 2.0, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 10.5, found 0.0\n",
      "Feature 3, split across: 8.5, found 0.0\n",
      "Feature 3, split across: 4.0, found 0.0\n",
      "Feature 3, split across: 2.0, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 15.5, found 0.0\n",
      "Feature 19, split across: 6.5, found 0.0\n",
      "Feature 19, split across: 3.0, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 27, split across: 14.0, found 0.0\n",
      "Feature 29, split across: 34.0, found 0.0\n",
      "Feature 29, split across: 16.0, found 0.0\n",
      "Feature 29, split across: 8.0, found 0.0\n",
      "Feature 29, split across: 4.0, found 0.0\n",
      "Feature 29, split across: 2.0, found 0.0\n",
      "Feature 29, split across: 1.0, found 0.0\n",
      "Feature 29, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 22.5, found 0.0\n",
      "Feature 28, split across: 10.5, found 0.0\n",
      "Feature 28, split across: 5.0, found 0.0\n",
      "Feature 28, split across: 2.5, found 0.0\n",
      "Feature 28, split across: 1.0, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 17, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.0, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 1.0, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 27, split across: 6.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 3.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 17, split across: 1.5, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 17, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 5, split across: 3.5, found 0.0\n",
      "Feature 5, split across: 1.5, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 18.5, found 0.0\n",
      "Feature 3, split across: 9.5, found 0.0\n",
      "Feature 3, split across: 4.5, found 0.0\n",
      "Feature 3, split across: 2.0, found 0.0\n",
      "Feature 3, split across: 1.0, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 22.5, found 0.0\n",
      "Feature 28, split across: 11.0, found 0.0\n",
      "Feature 28, split across: 5.5, found 0.0\n",
      "Feature 28, split across: 2.5, found 0.0\n",
      "Feature 28, split across: 1.0, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 8.5, found 0.0\n",
      "Feature 19, split across: 4.0, found 0.0\n",
      "Feature 19, split across: 2.0, found 0.0\n",
      "Feature 19, split across: 1.0, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 4.5, found 0.0\n",
      "Feature 12, split across: 2.0, found 0.0\n",
      "Feature 12, split across: 1.0, found 0.0\n",
      "Feature 12, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 16, split across: 2.5, found 0.0\n",
      "Feature 1, split across: 1.5, found 0.0\n",
      "Feature 1, split across: 0.5, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 7, split across: 1.0, found 0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 3.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 0.0\n",
      "Feature 20, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 18.0, found 0.0\n",
      "Feature 31, split across: 9.0, found 0.0\n",
      "Feature 8, split across: 1.0, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 9, split across: 2.5, found 0.0\n",
      "Feature 9, split across: 1.0, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 27.5, found 0.0\n",
      "Feature 13, split across: 16.5, found 0.0\n",
      "Feature 3, split across: 6.0, found 0.0\n",
      "Feature 3, split across: 3.0, found 0.0\n",
      "Feature 3, split across: 1.5, found 0.0\n",
      "Feature 3, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.5, found 0.0\n",
      "Feature 0, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 22.5, found 0.0\n",
      "Feature 28, split across: 10.5, found 0.0\n",
      "Feature 28, split across: 5.0, found 0.0\n",
      "Feature 28, split across: 2.5, found 0.0\n",
      "Feature 28, split across: 1.0, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 27, split across: 7.5, found 0.0\n",
      "Feature 19, split across: 6.5, found 0.0\n",
      "Feature 19, split across: 3.0, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 13, split across: 8.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 13, split across: 4.0, found 0.0\n",
      "Feature 13, split across: 2.0, found 0.0\n",
      "Feature 13, split across: 1.0, found 0.0\n",
      "Feature 13, split across: 0.5, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 2.5, found 0.0\n",
      "Feature 7, split across: 1.0, found 0.0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 17, split across: 2.0, found 0.0\n",
      "Feature 17, split across: 1.0, found 0.0\n",
      "Feature 17, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 11.0, found 0.0\n",
      "Feature 31, split across: 5.0, found 0.0\n",
      "Feature 31, split across: 2.5, found 0.0\n",
      "Feature 31, split across: 1.0, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 1.5, found 0.0\n",
      "Feature 21, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "{0: 13, 1: 2}\n",
      "0\n",
      "0.798\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-29af6f6bcf72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspamForestRoots\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mprintNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-29af6f6bcf72>\u001b[0m in \u001b[0;36mprintNode\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprintNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Level \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", feature \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_rule\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", split across: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_rule\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspamForestRoots\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "#Spam Training/Validation Random Forest\n",
    "\n",
    "indices = [i for i in range(len(spam_train_data))]\n",
    "random.shuffle(indices)\n",
    "\n",
    "copyData = []\n",
    "copyLabels = []\n",
    "\n",
    "validationData = []\n",
    "validationLabels = []\n",
    "\n",
    "for i in range(23000):\n",
    "    copyData.append(spam_train_data[indices[i]])\n",
    "    copyLabels.append(spam_train_labels[indices[i]])\n",
    "for i in range(22000,23000):\n",
    "    validationData.append(spam_train_data[indices[i]])\n",
    "    validationLabels.append(spam_train_labels[indices[i]])\n",
    "\n",
    "spamForestRoots = randomForestTrain(copyData, copyLabels, 50, 15)\n",
    "\n",
    "logging = True\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(len(validationData)):\n",
    "    if i >= 1: logging = False\n",
    "    transformed = validationData[i]\n",
    "    #prediction = nodeDecision(trainedCensusNode, transformed)\n",
    "    prediction = randomForestDecide(spamForestRoots, transformed)\n",
    "    #print(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "    if str(prediction) == str(validationLabels[i]):\n",
    "        accuracy += 1\n",
    "        \n",
    "accuracy /= len(validationLabels)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 10, split across: 2.0\n",
      "Feature 6, split across: 2.0\n",
      "Feature 31, split across: 33.5\n",
      "Feature 26, split across: 101.0\n",
      "Feature 9, split across: 1.5\n",
      "Feature 10, split across: 2.0\n",
      "Feature 0, split across: 3.5\n",
      "Feature 31, split across: 42.0\n",
      "Feature 10, split across: 2.0\n",
      "Feature 10, split across: 2.0\n",
      "Feature 20, split across: 1.5\n",
      "Feature 6, split across: 2.0\n",
      "Feature 10, split across: 2.0\n",
      "Feature 17, split across: 1.5\n",
      "Feature 9, split across: 2.5\n"
     ]
    }
   ],
   "source": [
    "#-----------\n",
    "\n",
    "def printNode(node):\n",
    "    print(\"Feature \" + str(node.split_rule[0]) + \", split across: \" + str(node.split_rule[1]))\n",
    "    \n",
    "for root in spamForestRoots:\n",
    "    printNode(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842\n",
      "Depth: 1, accuracy: 0.763\n",
      "Depth: 2, accuracy: 0.763\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-a136ca2df642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mtrainedCensusNode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfullTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingSetTransformed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopyLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7bbef2d52eb5>\u001b[0m in \u001b[0;36mfullTrain\u001b[0;34m(data, labels, levels, randomForest, checkAllSplits)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfullTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandomForest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckAllSplits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0minitialNode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitialNode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandomForest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minitialNode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7bbef2d52eb5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(node, data, labels, levels, randomForest, checkAllSplits)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegmenter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipFeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckAllSplits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mdecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegmenter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckAllSplits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-b71713c1f6c9>\u001b[0m in \u001b[0;36msegmenter\u001b[0;34m(data, labels, skipFeatures, checkAllSplits)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdataIndex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataIndex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatureIndex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mleft\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataIndex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mright\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataIndex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Census Train/Validation Normal\n",
    "\n",
    "indices = [i for i in range(len(census_train_csv))]\n",
    "random.shuffle(indices)\n",
    "\n",
    "copyData = []\n",
    "copyLabels = []\n",
    "\n",
    "validationData = []\n",
    "validationLabels = []\n",
    "\n",
    "for i in range(1000,int(len(census_train_csv) * 0.3)):\n",
    "    copyData.append(census_train_csv[indices[i]])\n",
    "    copyLabels.append(census_train_labels[indices[i]])\n",
    "for i in range(1000):\n",
    "    validationData.append(census_train_csv[indices[i]])\n",
    "    validationLabels.append(census_train_labels[indices[i]])\n",
    "    \n",
    "trainingSetTransformed = census_vec.transform(copyData)\n",
    "validSetTransformed = census_vec.transform(validationData)\n",
    "\n",
    "logprint(trainingSetTransformed)\n",
    "logprint(census_train_labels[30000:31000])\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "logging = False\n",
    "\n",
    "for i in range(len(validSetTransformed)):\n",
    "    transformed = validSetTransformed[i]\n",
    "    prediction = nodeDecision(trainedCensusNode, transformed)\n",
    "    #print(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "    if str(prediction) == str(validationLabels[i]):\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy /= len(validationLabels)\n",
    "\n",
    "print(accuracy)\n",
    "\n",
    "#--------\n",
    "\n",
    "logging = False\n",
    "\n",
    "for j in range(1,40):\n",
    "\n",
    "    trainedCensusNode = fullTrain(trainingSetTransformed, copyLabels, j)\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    for i in range(len(validSetTransformed)):\n",
    "        transformed = validSetTransformed[i]\n",
    "        prediction = nodeDecision(trainedCensusNode, transformed)\n",
    "        #print(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "        if str(prediction) == str(validationLabels[i]):\n",
    "            accuracy += 1\n",
    "\n",
    "    accuracy /= len(validationLabels)\n",
    "\n",
    "    print(\"Depth: \" + str(j) + \", accuracy: \" + str(accuracy))\n",
    "    \n",
    "    \"\"\"\n",
    "    Depth: 1, accuracy: 0.7628333333333334\n",
    "    Depth: 2, accuracy: 0.7628333333333334\n",
    "    Depth: 3, accuracy: 0.8241666666666667\n",
    "    Depth: 4, accuracy: 0.8298333333333333\n",
    "    Depth: 5, accuracy: 0.8315\n",
    "    Depth: 6, accuracy: 0.8328333333333333\n",
    "    Depth: 7, accuracy: 0.8358333333333333\n",
    "    Depth: 8, accuracy: 0.8398333333333333\n",
    "    Depth: 9, accuracy: 0.844\n",
    "    Depth: 10, accuracy: 0.846\n",
    "    Depth: 11, accuracy: 0.8483333333333334\n",
    "    Depth: 12, accuracy: 0.8506666666666667\n",
    "    Depth: 13, accuracy: 0.8606666666666667\n",
    "    Depth: 14, accuracy: 0.8651666666666666\n",
    "    Depth: 15, accuracy: 0.8705\n",
    "    Depth: 16, accuracy: 0.8751666666666666\n",
    "    Depth: 17, accuracy: 0.8785\n",
    "    Depth: 18, accuracy: 0.8821666666666667\n",
    "    Depth: 19, accuracy: 0.8865\n",
    "    Depth: 20, accuracy: 0.8905\n",
    "    Depth: 21, accuracy: 0.8955\n",
    "    Depth: 22, accuracy: 0.8978333333333334\n",
    "    Depth: 23, accuracy: 0.9021666666666667\n",
    "    Depth: 24, accuracy: 0.9065\n",
    "    Depth: 25, accuracy: 0.9088333333333334\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEPCAYAAABcA4N7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrv8Pdw4nnDH4WqoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc4cd128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xData = [i for i in range(1,29)]\n",
    "yData = [0.739, 0.739, 0.809, 0.828, 0.829, 0.827, 0.832, 0.831, 0.834, 0.83, 0.826, 0.828, 0.831, 0.832, 0.831, 0.834, 0.829, 0.832, 0.834, 0.83, 0.831, 0.827, 0.826, 0.825, 0.827, 0.826, 0.826, 0.83]\n",
    "plt.plot(xData, yData, 'b-')\n",
    "plt.axis([1, 25, 0.7, 0.9])\n",
    "plt.xlabel('Decision Tree Depth')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "\n",
    "testSetTransformed = census_vec.transform(census_test_csv)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(len(testSetTransformed)):\n",
    "    if i >= 10: logging = False\n",
    "    transformed = testSetTransformed[i]\n",
    "    prediction = nodeDecision(trainedCensusNode, transformed)\n",
    "    #print(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "    results.append([i+1, int(prediction)])\n",
    "    \n",
    "temp = np.asarray(results)\n",
    "#temp.tofile(\"./submission.py\")\n",
    "np.savetxt(\"census_submission.csv\", temp, fmt=\"%i,%i\", delimiter=\",\", header=\"Id,Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 1.5, found 40.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 15, split across: 6.5, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 230951.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 5, split across: 2.5, found 0.0\n",
      "Feature 5, split across: 1.0, found 0.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.0, found 230951.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 7.0, found 13.0\n",
      "Feature 12, split across: 13.5, found 0.0\n",
      "Ended at the decision: \n",
      "1\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 27.5, found 0.0\n",
      "Feature 31, split across: 13.5, found 0.0\n",
      "Feature 31, split across: 6.5, found 0.0\n",
      "Feature 31, split across: 3.0, found 0.0\n",
      "Feature 31, split across: 1.5, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 7.0, found 13.0\n",
      "Ended at the decision: \n",
      "1\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 16, split across: 4.5, found 0.0\n",
      "Feature 16, split across: 2.0, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 13, split across: 26.5, found 1.0\n",
      "Feature 13, split across: 13.0, found 1.0\n",
      "Feature 13, split across: 6.5, found 1.0\n",
      "Feature 13, split across: 3.0, found 1.0\n",
      "Feature 13, split across: 1.5, found 1.0\n",
      "Feature 13, split across: 0.5, found 1.0\n",
      "Feature 5, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 13.0, found 0.0\n",
      "Feature 16, split across: 4.5, found 0.0\n",
      "Feature 16, split across: 2.0, found 0.0\n",
      "Feature 16, split across: 1.0, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 6.5, found 0.0\n",
      "Feature 2, split across: 3.0, found 0.0\n",
      "Feature 2, split across: 1.5, found 0.0\n",
      "Feature 2, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 21, split across: 1.5, found 40.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 15, split across: 6.5, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 11.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 7.0, found 13.0\n",
      "Ended at the decision: \n",
      "1\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 33.5, found 0.0\n",
      "Feature 3, split across: 8.5, found 13.0\n",
      "Ended at the decision: \n",
      "1\n",
      "Feature 12, split across: 13.5, found 0.0\n",
      "Feature 6, split across: 1.5, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 1.0, found 50.0\n",
      "Ended at the decision: \n",
      "1\n",
      "Feature 19, split across: 10.0, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 5.0, found 0.0\n",
      "Feature 19, split across: 2.5, found 0.0\n",
      "Feature 19, split across: 1.0, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 230951.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 30.0, found 0.0\n",
      "Feature 29, split across: 49.5, found 0.0\n",
      "Feature 3, split across: 7.0, found 13.0\n",
      "Ended at the decision: \n",
      "1\n",
      "Feature 9, split across: 1.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 6.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 10.0, found 0.0\n",
      "Feature 19, split across: 3.5, found 0.0\n",
      "Feature 19, split across: 1.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 230951.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 2, split across: 14.5, found 0.0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 6.5, found 0.0\n",
      "Feature 31, split across: 33.0, found 0.0\n",
      "Feature 15, split across: 3.0, found 0.0\n",
      "Feature 15, split across: 1.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 30.0, found 0.0\n",
      "Feature 31, split across: 16.5, found 0.0\n",
      "Feature 31, split across: 7.5, found 0.0\n",
      "Feature 31, split across: 3.5, found 0.0\n",
      "Feature 31, split across: 1.5, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 1.5, found 230951.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 10, split across: 2.0, found 0.0\n",
      "Feature 10, split across: 1.0, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 33.0, found 0.0\n",
      "Feature 30, split across: 17.5, found 0.0\n",
      "Feature 31, split across: 16.5, found 0.0\n",
      "Feature 6, split across: 2.0, found 0.0\n",
      "Feature 6, split across: 1.0, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 8.5, found 13.0\n",
      "Ended at the decision: \n",
      "1\n",
      "{0: 8, 1: 7}\n",
      "0\n",
      "0.252\n"
     ]
    }
   ],
   "source": [
    "#Census Train/Validation Random Forest\n",
    "\n",
    "censusForestRoots = randomForestTrain(trainingSetTransformed, census_train_labels, 10, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1, split across: 49999.5, found 0.0\n",
      "Feature 80, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 37, split across: 0.5, found 0.0\n",
      "Feature 36, split across: 0.5, found 0.0\n",
      "Feature 53, split across: 0.5, found 0.0\n",
      "Feature 39, split across: 0.5, found 0.0\n",
      "Feature 56, split across: 0.5, found 0.0\n",
      "Feature 73, split across: 0.5, found 0.0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 71, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 34, split across: 0.5, found 0.0\n",
      "Feature 58, split across: 0.5, found 0.0\n",
      "Feature 80, split across: 0.5, found 0.0\n",
      "Feature 26, split across: 0.5, found 0.0\n",
      "Feature 33, split across: 0.5, found 0.0\n",
      "Feature 42, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 75, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 60, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 97, split across: 0.5, found 0.0\n",
      "Feature 80, split across: 0.5, found 0.0\n",
      "Feature 19, split across: 0.5, found 0.0\n",
      "Feature 48, split across: 0.5, found 0.0\n",
      "Feature 64, split across: 0.5, found 0.0\n",
      "Feature 65, split across: 0.5, found 0.0\n",
      "Feature 95, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 50.5, found 40.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 8.5, found 13.0\n",
      "Feature 58, split across: 0.5, found 0.0\n",
      "Feature 16, split across: 0.5, found 0.0\n",
      "Feature 101, split across: 0.5, found 0.0\n",
      "Feature 63, split across: 0.5, found 0.0\n",
      "Feature 92, split across: 0.5, found 0.0\n",
      "Feature 35, split across: 0.5, found 0.0\n",
      "Feature 41, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 99, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 50.5, found 40.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 35, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 26, split across: 0.5, found 0.0\n",
      "Feature 80, split across: 0.5, found 0.0\n",
      "Feature 76, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 75, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 0.5, found 0.0\n",
      "Feature 99, split across: 0.5, found 0.0\n",
      "Feature 80, split across: 0.5, found 0.0\n",
      "Feature 38, split across: 0.5, found 0.0\n",
      "Feature 59, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 3, split across: 8.0, found 13.0\n",
      "Feature 35, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 37, split across: 0.5, found 0.0\n",
      "Feature 12, split across: 0.5, found 0.0\n",
      "Feature 64, split across: 0.5, found 0.0\n",
      "Feature 73, split across: 0.5, found 0.0\n",
      "Feature 69, split across: 0.5, found 0.0\n",
      "Feature 53, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 0, split across: 53.5, found 50.0\n",
      "Feature 97, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 0.5, found 0.0\n",
      "Feature 80, split across: 0.5, found 0.0\n",
      "Feature 25, split across: 0.5, found 0.0\n",
      "Feature 37, split across: 0.5, found 0.0\n",
      "Feature 79, split across: 0.5, found 0.0\n",
      "Feature 64, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 18, split across: 0.5, found 0.0\n",
      "Feature 38, split across: 0.5, found 0.0\n",
      "Feature 64, split across: 0.5, found 0.0\n",
      "Feature 87, split across: 0.5, found 0.0\n",
      "Feature 80, split across: 0.5, found 0.0\n",
      "Feature 41, split across: 0.5, found 0.0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 53, split across: 0.5, found 0.0\n",
      "Feature 73, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 55, split across: 0.5, found 0.0\n",
      "Feature 62, split across: 0.5, found 0.0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 6, split across: 0.5, found 0.0\n",
      "Feature 11, split across: 0.5, found 0.0\n",
      "Feature 37, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 40, split across: 0.5, found 0.0\n",
      "Feature 106, split across: 0.5, found 0.0\n",
      "Feature 42, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 71, split across: 0.5, found 0.0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 33, split across: 0.5, found 0.0\n",
      "Feature 48, split across: 0.5, found 0.0\n",
      "Feature 23, split across: 0.5, found 0.0\n",
      "Feature 54, split across: 0.5, found 0.0\n",
      "Feature 73, split across: 0.5, found 0.0\n",
      "Feature 49, split across: 0.5, found 0.0\n",
      "Feature 60, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 71, split across: 0.5, found 0.0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Feature 13, split across: 0.5, found 1.0\n",
      "Feature 79, split across: 0.5, found 0.0\n",
      "Feature 94, split across: 0.5, found 0.0\n",
      "Feature 90, split across: 0.5, found 1.0\n",
      "Feature 100, split across: 0.5, found 0.0\n",
      "Feature 72, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 340589.0, found 230951.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 73, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 74, split across: 0.5, found 0.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Feature 49, split across: 0.5, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 106, split across: 0.5, found 0.0\n",
      "Feature 87, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 0.5, found 0.0\n",
      "Feature 95, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 528974.0, found 230951.0\n",
      "Feature 3, split across: 8.5, found 13.0\n",
      "Feature 49, split across: 0.5, found 0.0\n",
      "Feature 76, split across: 0.5, found 0.0\n",
      "Feature 69, split across: 0.5, found 0.0\n",
      "Feature 100, split across: 0.5, found 0.0\n",
      "Feature 96, split across: 0.5, found 0.0\n",
      "Feature 34, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 34, split across: 0.5, found 0.0\n",
      "Feature 52, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 0.5, found 0.0\n",
      "Feature 73, split across: 0.5, found 0.0\n",
      "Feature 35, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 0.5, found 0.0\n",
      "Feature 92, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 25, split across: 0.5, found 0.0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 62, split across: 0.5, found 0.0\n",
      "Feature 58, split across: 0.5, found 0.0\n",
      "Feature 24, split across: 0.5, found 1.0\n",
      "Feature 94, split across: 0.5, found 0.0\n",
      "Feature 90, split across: 0.5, found 1.0\n",
      "Feature 13, split across: 0.5, found 1.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 71, split across: 0.5, found 0.0\n",
      "Feature 93, split across: 0.5, found 0.0\n",
      "Feature 79, split across: 0.5, found 0.0\n",
      "Feature 9, split across: 0.5, found 0.0\n",
      "Feature 106, split across: 0.5, found 0.0\n",
      "Feature 11, split across: 0.5, found 0.0\n",
      "Feature 90, split across: 0.5, found 1.0\n",
      "Feature 55, split across: 0.5, found 0.0\n",
      "Feature 31, split across: 0.5, found 0.0\n",
      "Feature 20, split across: 590605.0, found 230951.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 98, split across: 0.5, found 1.0\n",
      "Feature 13, split across: 0.5, found 1.0\n",
      "Feature 26, split across: 0.5, found 0.0\n",
      "Feature 64, split across: 0.5, found 0.0\n",
      "Feature 100, split across: 0.5, found 0.0\n",
      "Feature 21, split across: 45.0, found 40.0\n",
      "Feature 75, split across: 0.5, found 0.0\n",
      "Feature 105, split across: 0.5, found 0.0\n",
      "Feature 68, split across: 0.5, found 1.0\n",
      "Feature 1, split across: 10025.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 3, split across: 8.5, found 13.0\n",
      "Feature 91, split across: 0.5, found 1.0\n",
      "Feature 71, split across: 0.5, found 0.0\n",
      "Feature 51, split across: 0.5, found 0.0\n",
      "Feature 23, split across: 0.5, found 0.0\n",
      "Feature 39, split across: 0.5, found 0.0\n",
      "Feature 52, split across: 0.5, found 0.0\n",
      "Feature 58, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 66, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 7, split across: 0.5, found 0.0\n",
      "Feature 34, split across: 0.5, found 0.0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 75, split across: 0.5, found 0.0\n",
      "Feature 99, split across: 0.5, found 0.0\n",
      "Feature 29, split across: 0.5, found 0.0\n",
      "Feature 4, split across: 0.5, found 0.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Feature 51, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 21, split across: 50.0, found 40.0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 96, split across: 0.5, found 0.0\n",
      "Feature 1, split across: 49999.5, found 0.0\n",
      "Feature 56, split across: 0.5, found 0.0\n",
      "Feature 73, split across: 0.5, found 0.0\n",
      "Feature 102, split across: 0.5, found 0.0\n",
      "Feature 71, split across: 0.5, found 0.0\n",
      "Feature 62, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 99, split across: 0.5, found 0.0\n",
      "Feature 15, split across: 0.5, found 0.0\n",
      "Feature 35, split across: 0.5, found 0.0\n",
      "Feature 95, split across: 0.5, found 0.0\n",
      "Feature 14, split across: 0.5, found 0.0\n",
      "Feature 11, split across: 0.5, found 0.0\n",
      "Feature 75, split across: 0.5, found 0.0\n",
      "Feature 62, split across: 0.5, found 0.0\n",
      "Feature 71, split across: 0.5, found 0.0\n",
      "Feature 73, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 50, split across: 0.5, found 0.0\n",
      "Feature 52, split across: 0.5, found 0.0\n",
      "Feature 60, split across: 0.5, found 0.0\n",
      "Feature 64, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 10, split across: 0.5, found 0.0\n",
      "Feature 94, split across: 0.5, found 0.0\n",
      "Feature 2, split across: 1587.5, found 0.0\n",
      "Feature 96, split across: 0.5, found 0.0\n",
      "Feature 101, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 46, split across: 0.5, found 0.0\n",
      "Feature 49, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 99, split across: 0.5, found 0.0\n",
      "Feature 95, split across: 0.5, found 0.0\n",
      "Feature 87, split across: 0.5, found 0.0\n",
      "Feature 72, split across: 0.5, found 0.0\n",
      "Feature 97, split across: 0.5, found 0.0\n",
      "Feature 11, split across: 0.5, found 0.0\n",
      "Feature 35, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "Feature 105, split across: 0.5, found 0.0\n",
      "Feature 30, split across: 0.5, found 0.0\n",
      "Feature 61, split across: 0.5, found 0.0\n",
      "Feature 97, split across: 0.5, found 0.0\n",
      "Feature 28, split across: 0.5, found 0.0\n",
      "Feature 87, split across: 0.5, found 0.0\n",
      "Feature 37, split across: 0.5, found 0.0\n",
      "Feature 40, split across: 0.5, found 0.0\n",
      "Feature 95, split across: 0.5, found 0.0\n",
      "Feature 8, split across: 0.5, found 0.0\n",
      "Ended at the decision: \n",
      "0\n",
      "{0: 25}\n",
      "0\n",
      "0.763\n"
     ]
    }
   ],
   "source": [
    "logging = True\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i in range(len(validSetTransformed)):\n",
    "    if i >= 1: logging = False\n",
    "    transformed = validSetTransformed[i]\n",
    "    #prediction = nodeDecision(trainedCensusNode, transformed)\n",
    "    prediction = randomForestDecide(censusForestRoots, transformed)\n",
    "    #print(str(prediction) + \" \" + str(validationLabels[i]))\n",
    "    if str(prediction) == str(validationLabels[i]):\n",
    "        accuracy += 1\n",
    "        \n",
    "accuracy /= len(validationLabels)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1, split across: 49999.5\n",
      "Feature 71, split across: 0.5\n",
      "Feature 60, split across: 0.5\n",
      "Feature 61, split across: 0.5\n",
      "Feature 50, split across: 0.5\n",
      "Feature 14, split across: 0.5\n",
      "Feature 15, split across: 0.5\n",
      "Feature 4, split across: 0.5\n",
      "Feature 15, split across: 0.5\n",
      "Feature 55, split across: 0.5\n",
      "Feature 7, split across: 0.5\n",
      "Feature 71, split across: 0.5\n",
      "Feature 73, split across: 0.5\n",
      "Feature 50, split across: 0.5\n",
      "Feature 14, split across: 0.5\n",
      "Feature 28, split across: 0.5\n",
      "Feature 71, split across: 0.5\n",
      "Feature 98, split across: 0.5\n",
      "Feature 3, split across: 8.5\n",
      "Feature 7, split across: 0.5\n",
      "Feature 21, split across: 50.0\n",
      "Feature 99, split across: 0.5\n",
      "Feature 50, split across: 0.5\n",
      "Feature 46, split across: 0.5\n",
      "Feature 105, split across: 0.5\n"
     ]
    }
   ],
   "source": [
    "for root in censusForestRoots:\n",
    "    printNode(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
